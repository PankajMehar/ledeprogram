{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#String operations and regular expressions\n",
    "\n",
    "Today we talk about strings. When we have a string, we might want to ask whether it has particular characteristics---does it start with a particular character? Does it contain within it another string?---or try to extract smaller parts of the string, like the first fifteen characters, or say, the part of the string inside parentheses. Or we may want to transform the string into another string altogether, by (for example) converting its characters to upper case, or replacing substrings within it with other substrings. Today we discuss how to do these things in Python.\n",
    "\n",
    "##Simple string checks\n",
    "\n",
    "There are a number of functions, methods and operators that can tell us whether or not a Python string matches certain characteristics. Let's talk about the `in` operator first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"foo\" in \"buffoon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"foo\" in \"reginald\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `in` operator takes one expression evaluating to a string on the left and another on the right, and returns `True` if the string on the left occurs somewhere inside of the string on the right.\n",
    "\n",
    "We can check to see if a string begins with or ends with another string using that string's `.startswith()` and `.endswith()` methods, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"foodie\".startswith(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"foodie\".endswith(\"foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.isdigit()` method returns `True` if Python thinks the string could represent an integer, and `False` otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print \"foodie\".isdigit()\n",
    "print \"4567\".isdigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `.islower()` and `.isupper()` methods return `True` if the string is in all lower case or all upper case, respectively (and `False` otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print \"foodie\".islower()\n",
    "print \"foodie\".isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print \"YELLING ON THE INTERNET\".islower()\n",
    "print \"YELLING ON THE INTERNET\".isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Finding substrings\n",
    "\n",
    "The `in` operator discussed above will tell us if a substring occurs in some other string. If we want to know *where* that substring occurs, we can use the `.find()` method. The `.find()` method takes a single parameter between its parentheses: an expression evaluating to a string, which will be searched for within the string whose `.find()` method was called. If the substring is found, the entire expression will evaluate to the index at which the substring is found. If the substring is not found, the expression evaluates to `-1`. To demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print \"Now is the winter of our discontent\".find(\"win\")\n",
    "print \"Now is the winter of our discontent\".find(\"lose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.count()` method will return the number of times a particular substring is found within the larger string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print \"I got rhythm, I got music, I got my man, who could ask for anything more\".count(\"I got\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##String slices\n",
    "\n",
    "As has been alluded to previously, string slices work exactly like list slices---except you're getting characters from the string, instead of elements from a list. Observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"bungalow\"\n",
    "message[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ungal'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bun'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ngalow'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine this with the `find()` method and you can do things like write expressions that evaluate to everything from where a substring matches, up to the end of the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winter of our discontent\n"
     ]
    }
   ],
   "source": [
    "shakespeare = \"Now is the winter of our discontent\"\n",
    "substr_index = shakespeare.find(\"win\")\n",
    "print shakespeare[substr_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Simple string transformations\n",
    "\n",
    "Python strings have a number of different methods which, when called on a string, return a copy of that string with a simple transformation applied to it. These are helpful for normalizing and cleaning up data, or preparing it to be displayed.\n",
    "\n",
    "Let's start with `.lower()`, which evaluates to a copy of the string in all lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'argumentation! disagreement! strife!'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ARGUMENTATION! DISAGREEMENT! STRIFE!\".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The converse of `.lower()` is `.upper()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.E. CUMMINGS IS. NOT. HAPPY ABOUT THIS.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"e.e. cummings is. not. happy about this.\".upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.title()` evaluates to a copy of the string it's called on, replacing every letter at the beginning of a word in the string with a capital letter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dr. Strangelove, Or, How I Learned To Love The Bomb'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"dr. strangelove, or, how I learned to love the bomb\".title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.strip()` method removes any whitespace from the beginning or end of the string (but not between characters later in the string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'got some random whitespace in some places here'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" got some random whitespace in some places here     \".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `.replace()` method takes two parameters: a string to find, and a string to replace that string with whenever it's found. You can use this to make sad stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I used to have rhythm, I used to have music, I used to have my man, who could ask for anything more'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I got rhythm, I got music, I got my man, who could ask for anything more\".replace(\"I got\", \"I used to have\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\"Escape\" sequences in strings\n",
    "\n",
    "Inside of strings that you type into your Python code, there are certain sequences of characters that have a special meaning. These sequences start with a backslash character (`\\`) and allow you to insert into your string characters that would otherwise be difficult to type, or that would go against Python syntax. Here's some code illustrating a few common sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include \"double quotes\" (inside of a double-quoted string)\n",
      "include 'single quotes' (inside of a single-quoted string)\n",
      "one\ttab, two\ttabs\n",
      "new\n",
      "line\n",
      "include an actual backslash \\ (two backslashes in the string)\n"
     ]
    }
   ],
   "source": [
    "print \"include \\\"double quotes\\\" (inside of a double-quoted string)\"\n",
    "print 'include \\'single quotes\\' (inside of a single-quoted string)'\n",
    "print \"one\\ttab, two\\ttabs\"\n",
    "print \"new\\nline\"\n",
    "print \"include an actual backslash \\\\ (two backslashes in the string)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Regular expressions\n",
    "\n",
    "So far, we've discussed how to write programs and expressions that are able to check whether strings meet very simple criteria, such as “does this string begin with a particular character” or “does this string contain another string”? But imagine writing a program that performs the following task: find and print all ZIP codes in a string (i.e., a five-character sequence of digits). Give up? Here’s my attempt, using only the tools we’ve discussed so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12345', '45678', '23456']\n"
     ]
    }
   ],
   "source": [
    "input_str = \"here's a zip code: 12345. 567 isn't a zip code, but 45678 is. 23456? yet another zip code.\"\n",
    "current = \"\"\n",
    "zips = []\n",
    "for ch in input_str:\n",
    "    if ch in '0123456789':\n",
    "        current += ch\n",
    "    else:\n",
    "        current = \"\"\n",
    "    if len(current) == 5:\n",
    "        zips.append(current)\n",
    "        current = \"\"\n",
    "print zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we have to iterate over each character in the string, check to see if that character is a digit, append to a string variable if so, continue reading characters until we reach a non-digit character, check to see if we found exactly five digit characters, and add it to a list if so. At the end, we print out the list that has all of our results. Problems with this code: it’s messy; it doesn’t overtly communicate what it’s doing; it’s not easily generalized to other, similar tasks (e.g., if we wanted to write a program that printed out phone numbers from a string, the code would likely look completely different).\n",
    "\n",
    "Our ancient UNIX pioneers had this problem, and in pursuit of a solution, thought to themselves, \"Let’s make a tiny language that allows us to write specifications for textual patterns, and match those patterns against strings. No one will ever have to write fiddly code that checks strings character-by-character ever again.\" And thus regular expressions were born.\n",
    "\n",
    "Here's the code for accomplishing the same task with regular expressions, by the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12345', '45678', '23456']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "zips = re.findall(r\"\\d{5}\", input_str)\n",
    "print zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I’ll allow that the `r\"\\d{5}\"` in there is mighty cryptic (though hopefully it won’t be when you’re done reading this page and/or participating in the associated lecture). But the overall structure of the program is much simpler.\n",
    "\n",
    "###Fetching our corpus\n",
    "\n",
    "For this section of class, we'll be using the subject lines of all e-mails in the [EnronSent corpus](http://verbs.colorado.edu/enronsent/), kindly put into the public domain by the United States Federal Energy Regulatory Commission. Download a copy into your notebook directory like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('enronsubjects.txt', <httplib.HTTPMessage instance at 0x1049019e0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "urllib.urlretrieve(\"https://raw.githubusercontent.com/ledeprogram/courses/master/databases/data/enronsubjects.txt\", \"enronsubjects.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Matching strings with regular expressions\n",
    "\n",
    "The most basic operation that regular expressions perform is matching strings: you’re asking the computer whether a particular string matches some description. We're going to be using regular expressions to print only those lines from our `enronsubjects.txt` corpus that match particular sequences. Let's load our corpus into a list of lines first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# This file contains the subject lines from every message in the EnronSent corpus.',\n",
       " '# For more information, see http://verbs.colorado.edu/enronsent',\n",
       " '',\n",
       " 'Headcount',\n",
       " 'utilities roll',\n",
       " 'utilities roll',\n",
       " 'TIME SENSITIVE: Executive Impact & Influence Program Survey',\n",
       " 'TIME SENSITIVE: Executive Impact & Influence Program Survey',\n",
       " 'Wow',\n",
       " 'Wow',\n",
       " 'Wow',\n",
       " 'Wow',\n",
       " 'Re:',\n",
       " 'Re:',\n",
       " 'Re:',\n",
       " 'RE: Receipt of Team Selection Form - Executive Impact & Influence',\n",
       " 'RE: Receipt of Team Selection Form - Executive Impact & Influence',\n",
       " 'Receipt of Team Selection Form - Executive Impact & Influence',\n",
       " 'FYI',\n",
       " 'FYI',\n",
       " 'Re: Transportation Reports',\n",
       " 'Re: Western Gas Market Report -- Draft',\n",
       " 'Receipt of Team Selection Form - Executive Impact & Influence',\n",
       " 'Receipt of Team Selection Form - Executive Impact & Influence Program',\n",
       " 'Re: (No Subject)',\n",
       " 'Re: Security Request: CLOG-4NNJEZ has been Denied.',\n",
       " 'New Generation',\n",
       " 'New Generation',\n",
       " 'Re: Meeting to discuss 2001 direct expense plan?',\n",
       " 'Re: regulatory filing summary',\n",
       " 'Re: Evaluation for new trading application',\n",
       " 'Re: receipts',\n",
       " 'Re: ENA Fileplan Project - Needs your approval',\n",
       " \"Enron's December physical fixed price deals as of 11/28/00\",\n",
       " \"Enron's December physical fixed price deals as of 11/28/00\",\n",
       " 'Re: checkbook and budget',\n",
       " 'Daily Duties',\n",
       " 'Daily Duties',\n",
       " 'Daily Report',\n",
       " 'Daily Report',\n",
       " 'Daily Report',\n",
       " 'Daily Report',\n",
       " 'Re: enron close to 85',\n",
       " 'Re:',\n",
       " 'ENA Management Committee',\n",
       " 'ENA Management Committee',\n",
       " 'rent roll',\n",
       " 'rent roll',\n",
       " 'Re:',\n",
       " 'Re: Your approval is requested',\n",
       " 'tv on 33',\n",
       " 'Re: Ad Hoc VaR model',\n",
       " 'TRANSPORTATION MODEL',\n",
       " 'TRANSPORTATION MODEL',\n",
       " 'Re: TRANSPORTATION MODEL',\n",
       " 'Your Approval is Overdue: Access Request for paul.t.lucci@enron.com',\n",
       " 'Your Approval is Overdue: Access Request for paul.t.lucci@enron.com',\n",
       " 'Your Approval is Overdue: Access Request for paul.t.lucci@enron.com',\n",
       " 'Request Submitted: Access Request for frank.ermis@enron.com',\n",
       " 'Request Submitted: Access Request for frank.ermis@enron.com',\n",
       " 'Re: Nortel box',\n",
       " 'Re: trading opportunities',\n",
       " 'New Socal Curves',\n",
       " 'New Socal Curves',\n",
       " 'Re: Report on Property',\n",
       " 'Gas fundamentals development website',\n",
       " 'Gas fundamentals development website',\n",
       " 'Re: Electric Overage (1824.62)',\n",
       " 'New Generation Update 7/24/00',\n",
       " 'New Generation Update 7/24/00',\n",
       " 'Re: New Notice from Transwestern Pipeline Co.',\n",
       " 'Re: SM134 Proforma.xls',\n",
       " 'Price for Stanfield Term',\n",
       " 'Price for Stanfield Term',\n",
       " 'For Wade',\n",
       " 'Re: your address',\n",
       " 'Interactive Information Resource',\n",
       " 'Interactive Information Resource',\n",
       " 'Re: lunch',\n",
       " 'Comments on Order 637 Compliance Filings',\n",
       " 'Comments on Order 637 Compliance Filings',\n",
       " 'El Paso Blanco Avg product',\n",
       " 'El Paso Blanco Avg product,',\n",
       " 'Re: 65th BD for Nea',\n",
       " 'Project Elvis and Cactus Open Gas Position',\n",
       " 'Project Elvis and Cactus Open Gas Position',\n",
       " 'Re: West Gas Trading 2001 Plan',\n",
       " 'assoc. for west desk',\n",
       " 'assoc. for west desk',\n",
       " 'assoc. for west desk',\n",
       " 'assoc. for west desk',\n",
       " 'assoc. for west desk',\n",
       " 'Systems Meeting 7/18',\n",
       " 'Systems Meeting 7/18',\n",
       " 'assoc. for west desk',\n",
       " 'Re: Katy flatlands',\n",
       " 'Re: New Notice from Transwestern Pipeline Co.',\n",
       " 'test',\n",
       " 'System Meeting 7/11',\n",
       " 'System Meeting 7/11',\n",
       " 'Natural Gas Customers',\n",
       " 'Natural Gas Customers',\n",
       " 'Natural Gas Customers',\n",
       " 'Re: EXECUTIVE IMPACT COURSE',\n",
       " 'SM134 Proforma.xls',\n",
       " 'SM134 Proforma.xls',\n",
       " 'Re: Katy flatlands',\n",
       " 'Re: Brenda Stones telephone numbers',\n",
       " 'Re: market intelligence',\n",
       " 'Re: Memory',\n",
       " 'Re: Thoughts on Presentation',\n",
       " 'Executive Impact and Influence Course',\n",
       " 'Executive Impact and Influence Course',\n",
       " 'Re: Notices',\n",
       " '(Reminder) Update GIS Information',\n",
       " '(Reminder) Update GIS Information',\n",
       " 'West Power Strategy Materials',\n",
       " 'West Power Strategy Materials',\n",
       " 'Re: West Gas 2001 Plan',\n",
       " 'Re: West Gas 2001 Plan',\n",
       " 'gas storage model',\n",
       " 'gas storage model',\n",
       " 'Re:',\n",
       " 'Re:',\n",
       " 'Download Frogger before it hops away!',\n",
       " 'Download Frogger before it hops away!',\n",
       " 'FT-Denver book on EOL',\n",
       " 'FT-Denver book on EOL',\n",
       " 'Re: The New Power Company',\n",
       " 'Re: Wade',\n",
       " 'Thoughts on Presentation',\n",
       " 'Thoughts on Presentation',\n",
       " 'Enron Response to San Diego Request for Gas Price Caps',\n",
       " 'Enron Response to San Diego Request for Gas Price Caps',\n",
       " 'Re: West Gas 2001 Plan',\n",
       " 'Re: West Gas 2001 Plan',\n",
       " 'Re: Compaq M700 laptop',\n",
       " 'RE: 91 acres',\n",
       " \"Re: What's happening?\",\n",
       " 'Transport p&l',\n",
       " 'Transport p&l',\n",
       " 'Re: balance on truck/loan',\n",
       " 'Re: San Marcos Study',\n",
       " 'Re: Todays update',\n",
       " 'Gas Transportation Market Intelligence',\n",
       " 'Gas Transportation Market Intelligence',\n",
       " 'Re: 91 acres',\n",
       " 'Large Deal Alert',\n",
       " 'Large Deal Alert',\n",
       " 'Large Deal Alert',\n",
       " 'Re: 5/08/00',\n",
       " 'Re: DSL- Installs',\n",
       " 'Re: SW Gas',\n",
       " 'Re: SW Gas',\n",
       " 'SW Gas',\n",
       " 'SW Gas',\n",
       " 'SW Gas',\n",
       " 'Re: #30',\n",
       " 'Western Strategy Session Materials',\n",
       " 'Western Strategy Session Materials',\n",
       " 'Western Strategy Session Materials',\n",
       " 'Western Strategy Session Materials',\n",
       " 'Re: #30',\n",
       " 'Re: Foundation leveling on #2 & #3 apts.',\n",
       " 'Re: DSL Install',\n",
       " 'Re: Payroll Reclasses',\n",
       " 'Alliance netback worksheet',\n",
       " 'Alliance netback worksheet',\n",
       " 'Alliance netback worksheet',\n",
       " 'Alliance netback worksheet',\n",
       " 'New Employee on 32',\n",
       " 'New Employee on 32',\n",
       " 'RE: Inspection for Mission South',\n",
       " 'Re: your moms birthday',\n",
       " 'Re: Inspection for Mission South',\n",
       " 're: storm results & refrigerators',\n",
       " 'Western Strategy Briefing Materials',\n",
       " 'Western Strategy Briefing Materials',\n",
       " 'Re: MS 150',\n",
       " 'Meeting-THURSDAY, MARCH 23 - 11:15 AM',\n",
       " 'Meeting-THURSDAY, MARCH 23 - 11:15 AM',\n",
       " 'Re: Maps',\n",
       " 'Re: Resumes',\n",
       " 'Maps',\n",
       " 'Maps',\n",
       " 'Re:',\n",
       " 'Maps',\n",
       " 'Maps',\n",
       " 'Re: 220,000 MW of New Capacity Needed by 2012',\n",
       " 're: apt. #2',\n",
       " 'Priority List',\n",
       " 'Priority List',\n",
       " 'Re: West Gas 2001 Plan',\n",
       " 'Priority List',\n",
       " 're: apt. #2',\n",
       " 'RE: a/c for #27',\n",
       " 'Re: Mission South',\n",
       " 'Re:',\n",
       " 'Western Strategy Summaries',\n",
       " 'Western Strategy Summaries',\n",
       " 'Re:',\n",
       " 'ALLEN DURANGO HOTEL ------- 48 HR CANCEL',\n",
       " 'ALLEN DURANGO HOTEL ------- 48 HR CANCEL',\n",
       " 'ALLEN DURANGO HOTEL ------- 48 HR CANCEL',\n",
       " 'Just Released! Exclusive new animation from Stan Lee',\n",
       " 'Just Released! Exclusive new animation from Stan Lee',\n",
       " 'Re: Feb. Expense Report',\n",
       " 'Re: 91acres',\n",
       " \"PIRA's California/Southwest Gas Pipeline Study\",\n",
       " \"PIRA's California/Southwest Gas Pipeline Study\",\n",
       " \"PIRA's California/Southwest Gas Pipeline Study\",\n",
       " 'Re: Desk to Desk access Request',\n",
       " 'Re: February expenses',\n",
       " 'Re:',\n",
       " 'Storage of Cycles at the Body Shop',\n",
       " 'Storage of Cycles at the Body Shop',\n",
       " 'New Generation as of Oct 24th',\n",
       " 'New Generation as of Oct 24th',\n",
       " 'Western Strategy Briefing',\n",
       " 'Western Strategy Briefing',\n",
       " 'RE: W basis quotes',\n",
       " 'RE: W basis quotes',\n",
       " 'RE: W basis quotes',\n",
       " 'RE: W basis quotes',\n",
       " 'Re: APEA - $228,204 hit',\n",
       " 'Re: W basis quotes',\n",
       " 'Re: January El paso invoice',\n",
       " 'Re: Kim Olinger - Transport Rate Team',\n",
       " 'Re: APEA - $228,204 hit',\n",
       " 'Re: Curve Update',\n",
       " 'Re: Website Access approval requested',\n",
       " 'Re: Vishal Apte',\n",
       " 'dopewars',\n",
       " 'dopewars',\n",
       " 'dopewars',\n",
       " 'RE: Choosing a style',\n",
       " 'RE: Choosing a style',\n",
       " 'Choosing a style',\n",
       " 'Re:',\n",
       " 'Re: ENROLLMENT CONFIRMATION/Impact/ECT',\n",
       " 'eol',\n",
       " 'Re: Resumes',\n",
       " 'Re:',\n",
       " 'Re:',\n",
       " 'Re: receipts',\n",
       " 'Re: Are you trying to be funny?',\n",
       " 'Stick it in your Shockmachine!',\n",
       " 'Stick it in your Shockmachine!',\n",
       " 'Talking points about California Gas market',\n",
       " 'Talking points about California Gas market',\n",
       " 'Resumes',\n",
       " 'Resumes',\n",
       " 'Re: 2- SURVEY/INFORMATION EMAIL 5-14- 01',\n",
       " '2- SURVEY/INFORMATION EMAIL 5-14- 01',\n",
       " 'Re:',\n",
       " 'California Summary',\n",
       " 'California Summary',\n",
       " 'Additional California Load Information',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'California Update 5/4/01',\n",
       " 'California Update 5/4/01',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re:',\n",
       " 'Re: Inquiry....',\n",
       " 'Re: 2- SURVEY - PHILLIP ALLEN',\n",
       " 'Re: 2- SURVEY - PHILLIP ALLEN',\n",
       " '4-URGENT - OWA Please print this now.',\n",
       " '4-URGENT - OWA Please print this now.',\n",
       " '2- SURVEY/INFORMATION EMAIL',\n",
       " '2- SURVEY/INFORMATION EMAIL',\n",
       " 'Re: Request from Steve Kean',\n",
       " 'Request from Steve Kean',\n",
       " 'Request from Steve Kean',\n",
       " 'Request from Steve Kean',\n",
       " 'Request from Steve Kean',\n",
       " 'Request from Steve Kean',\n",
       " 'Request from Steve Kean',\n",
       " 'Re: Analyst Resume - Rafael Avila',\n",
       " 'Re: Inquiry....',\n",
       " 'Re: Leander etc.',\n",
       " 'Re:',\n",
       " \"Re: FERC's Prospective Mitigation and Monitoring Plan for CA\",\n",
       " 'Re: Unocal WAHA Storage',\n",
       " \"Re: This morning's Commission meeting delayed\",\n",
       " \"Re: This morning's Commission meeting delayed\",\n",
       " \"Re: This morning's Commission meeting delayed\",\n",
       " \"Re: This morning's Commission meeting delayed\",\n",
       " 'Re: Instructions for FERC Meetings',\n",
       " 'Instructions for FERC Meetings',\n",
       " 'Instructions for FERC Meetings',\n",
       " 'Instructions for FERC Meetings',\n",
       " 'Re:',\n",
       " 'Generation',\n",
       " 'Generation',\n",
       " 'Re: The Stage',\n",
       " 'Re: Analyst Ashish Mahajan',\n",
       " 'Re: Resume',\n",
       " 'Re: Analyst Bryan Hull',\n",
       " 'Re: FW: Trading Track Program',\n",
       " 'Re: Do you still access data from Inteligence Press online??',\n",
       " 'RE: Presentation to Trading Track A&A',\n",
       " 'RE: Presentation to Trading Track A&A',\n",
       " 'Re: Presentation to Trading Track A&A',\n",
       " 'Re: Approval for Plasma Screens',\n",
       " 'Re: Resume',\n",
       " 'Re: FW: 2nd lien info. and private lien info - The Stage Coach',\n",
       " 'Re: Presentation to Trading Track A&A',\n",
       " 'approved trader list',\n",
       " 'approved trader list',\n",
       " 'Re: insurance - the stage',\n",
       " 'RE: The Stage',\n",
       " 'Re: The Stage',\n",
       " 'CAISO demand reduction',\n",
       " 'CAISO demand reduction',\n",
       " 'Re: FW: SanJuan/SoCal spread prices',\n",
       " 'Re: SanJuan/SoCal spread prices',\n",
       " 'SanJuan/SoCal spread prices',\n",
       " 'SanJuan/SoCal spread prices',\n",
       " 'Re:',\n",
       " 'Re: Astral downtime request',\n",
       " 'Re: Answers to List',\n",
       " 'EES Gas Desk Happy Hour',\n",
       " 'EES Gas Desk Happy Hour',\n",
       " 'Re: Location',\n",
       " 'Enron Center Garage',\n",
       " 'Enron Center Garage',\n",
       " 'Re:',\n",
       " 'Re: Approval for Plasma Screens',\n",
       " 'Nondeliverable mail',\n",
       " 'Nondeliverable mail',\n",
       " 'Nondeliverable mail',\n",
       " 'Nondeliverable mail',\n",
       " 'Re: Opening Day - Baseball Tickets',\n",
       " 'November fixed-price deals',\n",
       " 'November fixed-price deals',\n",
       " 'Re: NGI access to eol',\n",
       " 'Re: NGI access to eol',\n",
       " 'Re: Derek Kelly',\n",
       " 'Re: Purchase and Sale Agreement',\n",
       " 'Current Gas Desk List',\n",
       " 'Current Gas Desk List',\n",
       " 'Re:',\n",
       " 'Re: Buyout',\n",
       " 'ERMS / RMS Databases',\n",
       " 'ERMS / RMS Databases',\n",
       " 'RE: Buyout',\n",
       " 'RE: Buyout',\n",
       " 'Re: Buyout',\n",
       " 'Your Approval is Overdue: Access Request for mike.grigsby@enron.com',\n",
       " 'Your Approval is Overdue: Access Request for mike.grigsby@enron.com',\n",
       " 'Re: Buyout',\n",
       " 'Matt Smith',\n",
       " 'Matt Smith',\n",
       " 'Re: Confidential Employee Information/Lenhart',\n",
       " 'Behind the Stage Two',\n",
       " 'Behind the Stage Two',\n",
       " 'RE: PERSONAL AND CONFIDENTIAL COMPENSATION INFORMATION',\n",
       " 'Re: (No Subject)',\n",
       " 'Sagewood M/F',\n",
       " 'Sagewood M/F',\n",
       " 'Bishops Corner, Ltd. Buyout',\n",
       " 'Bishops Corner, Ltd. Buyout',\n",
       " 'Bishops Corner, Ltd. -- Restructure or Buyout',\n",
       " 'Bishops Corner, Ltd. Buyout',\n",
       " 'Bishops Corner, Ltd. Buyout',\n",
       " 'Bishops Corner, Ltd. -- Restructure or Buyout',\n",
       " 'FW: ALL 1099 TAX QUESTIONS - ANSWERED',\n",
       " 'FW: ALL 1099 TAX QUESTIONS - ANSWERED',\n",
       " 'matt Smith',\n",
       " 'matt Smith',\n",
       " 'Mike Grigsby',\n",
       " 'Sagewood Phase II',\n",
       " 'Sagewood Phase II',\n",
       " 'Sagewood Phase II',\n",
       " 'Re: San Marcos',\n",
       " 'Revised Long Range Hydro Forecast',\n",
       " 'Revised Long Range Hydro Forecast',\n",
       " 'RE: the stage',\n",
       " 'Re: the stage',\n",
       " 'Re: password',\n",
       " 'Re: MS 150',\n",
       " 'FW: Cross Commodity',\n",
       " 'FW: Cross Commodity',\n",
       " 'Cross Commodity',\n",
       " 'Re: Insight Hardware',\n",
       " 'Re: Producer Services',\n",
       " \"Re: Enron's March Basdeload Fixed price physical deals as of 2/27\",\n",
       " \"Re: Enron's March Basdeload Fixed price physical deals as of 2/27\",\n",
       " \"Re: Enron's March Basdeload Fixed price physical deals as of 2/27\",\n",
       " \"Re: Enron's March Basdeload Fixed price physical deals as of 2/27\",\n",
       " 'San Marcos construction project',\n",
       " 'Re: Genesis Plant Tour',\n",
       " 'RE: Comparison of Estimates',\n",
       " 'Sagewood II',\n",
       " 'Sagewood II',\n",
       " 'New Generation Report for January 2001',\n",
       " 'New Generation Report for January 2001',\n",
       " 'Re: Comparison of Estimates',\n",
       " 'Recession Scenario Impact on Power and Gas',\n",
       " 'Recession Scenario Impact on Power and Gas',\n",
       " 'SM134 Proforma2.xls',\n",
       " 'SM134 Proforma2.xls',\n",
       " 'Re: Weekly Status Meeting',\n",
       " 'Weekly Status Meeting',\n",
       " 'Weekly Status Meeting',\n",
       " 'leander and the Stage',\n",
       " 'leander and the Stage',\n",
       " 'Daily California Call Moved to Weekly Call',\n",
       " 'Daily California Call Moved to Weekly Call',\n",
       " 'SM134 Proforma2.xls',\n",
       " 'SM134 Proforma2.xls',\n",
       " 'Re: FW: Change in the agroup Cycling Schedule',\n",
       " 'Re: General Issues',\n",
       " 'Re:',\n",
       " 'Re: General Issues',\n",
       " 'Re: DRAW2.xls',\n",
       " 'Re:',\n",
       " 'DRAW2.xls',\n",
       " 'DRAW2.xls',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'Re: MAI Appraisal',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'Re:',\n",
       " 'CERA Analysis - California',\n",
       " 'CERA Analysis - California',\n",
       " 'Re: Great Web Site',\n",
       " 'Re: EXTRINSIC VALUE WORKSHEET',\n",
       " 'Re: AEC Volumes at OPAL',\n",
       " 'Re: AEC Volumes at OPAL',\n",
       " 'AEC Volumes at OPAL',\n",
       " 'AEC Volumes at OPAL',\n",
       " 'California Gas Demand Growth',\n",
       " 'California Gas Demand Growth',\n",
       " 'the stage',\n",
       " 'the stage',\n",
       " 'Investment Structure',\n",
       " 'Investment Structure',\n",
       " 'Re: stage coach',\n",
       " 'Governor Reports Results of 1st RFP -- ONLY 500 MW!!!!',\n",
       " 'Governor Reports Results of 1st RFP -- ONLY 500 MW!!!!',\n",
       " 'Smeltering',\n",
       " 'Smeltering',\n",
       " 'Re: Listing of Desk Directors',\n",
       " 'Re: Pipe Options Book Admin Role',\n",
       " 're: book admin for Pipe/Gas daily option book',\n",
       " 're: book admin for Pipe/Gas daily option book',\n",
       " 're: book admin for Pipe/Gas daily option book',\n",
       " 'final business points',\n",
       " 're: book admin for Pipe/Gas daily option book',\n",
       " 're: book admin for Pipe/Gas daily option book',\n",
       " 'RE: Phillip Allen Response on Partnership Issues',\n",
       " 'Re: web site',\n",
       " 'Re: web site',\n",
       " 'Re: Enron',\n",
       " 'Re: The Stage',\n",
       " 'Highlights of Executive Summary by KPMG -- CPUC Audit Report on',\n",
       " 'Highlights of Executive Summary by KPMG -- CPUC Audit Report on=20',\n",
       " 'CPUC posts audit reports',\n",
       " 'CPUC posts audit reports',\n",
       " 'Re: Bishops Corner Partnership',\n",
       " 'RE:Stock Options',\n",
       " 'RE:Stock Options',\n",
       " 'Re: 32 acres',\n",
       " 'Re: SM134',\n",
       " 'Re: SM134',\n",
       " 'RE: Loan for San Marcos',\n",
       " 'Re: NGI access to eol',\n",
       " 'Enron',\n",
       " 'NGI access to eol',\n",
       " 'NGI access to eol',\n",
       " 'Status of QF negotiations on QFs & Legislative Update',\n",
       " 'Status of QF negotiations on QFs & Legislative Update',\n",
       " 'Status of QF negotiations on QFs & Legislative Update',\n",
       " 'Analyst Interviews Needed - 2/15/01',\n",
       " 'Analyst Interviews Needed - 2/15/01',\n",
       " 'Re: Resume',\n",
       " 'Kidventure Camp',\n",
       " 'Kidventure Camp',\n",
       " 'Re: Draft of Opposition to ORA/TURN petition',\n",
       " 'Re: Draft of Opposition to ORA/TURN petition',\n",
       " 'Re: Response to PGE request for gas',\n",
       " 'Re: Response to PGE request for gas',\n",
       " 'Response to PGE request for gas',\n",
       " 'Re: Please respond',\n",
       " 'Re: Please respond',\n",
       " 'California Action Update 1-14-00',\n",
       " 'California Action Update 1-14-00',\n",
       " 'California - Jan 13 meeting',\n",
       " 'California - Jan 13 meeting',\n",
       " 'Re:',\n",
       " 'Re: Analyst Rotating',\n",
       " 'Re: EOL Screens in new Body Shop',\n",
       " 'Analyst Rotating',\n",
       " 'Analyst Rotating',\n",
       " 'Preliminary 2001 Northwest Hydro Outlook',\n",
       " 'Preliminary 2001 Northwest Hydro Outlook',\n",
       " 'updated lease information',\n",
       " 'Re: Wiring instructions',\n",
       " 'Re: Analyst PRC',\n",
       " 'Re: SM134',\n",
       " 'Re: test',\n",
       " 'Re: Needs Assessment Form',\n",
       " 'Re: Untitled.exe Untitled.exe [22/23]',\n",
       " 'Re: SM134 Balcones Bank Loan',\n",
       " 'New Generation, Nov 30th',\n",
       " 'New Generation, Nov 30th',\n",
       " 'New Generation, Nov 30th',\n",
       " 'Meeting with Governor Davis, need for additional',\n",
       " 'Meeting with Governor Davis, need for additional comments/suggestions',\n",
       " 'Re: High Speed Internet Access',\n",
       " 'Re: Global Ids',\n",
       " 'Re: Global Ids',\n",
       " 'RE: access',\n",
       " 'RE: access',\n",
       " 'Re: Your Approval is Overdue: Access Request for',\n",
       " 'Your Approval is Overdue: Access Request for barry.tycholiz@enron.com',\n",
       " 'Re: SM134 Proforma.xls',\n",
       " 'FW: fixed forward or other Collar floor gas price terms',\n",
       " 'FW: fixed forward or other Collar floor gas price terms',\n",
       " 'Re:',\n",
       " 'Re: Call saturday',\n",
       " 'Re:',\n",
       " 'Re:',\n",
       " 'Re:',\n",
       " 'Final FIled Version',\n",
       " 'Final FIled Version',\n",
       " 'Re: FW: fixed forward or other Collar floor gas price terms',\n",
       " 'Consolidated positions: Issues & To Do list',\n",
       " 'Consolidated positions: Issues & To Do list',\n",
       " 'Consolidated positions: Issues & To Do list',\n",
       " 'Consolidated positions: Issues & To Do list',\n",
       " 'Consolidated positions: Issues & To Do list',\n",
       " 'Consolidated positions: Issues & To Do list',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'Re: 2001 Margin Plan',\n",
       " 'Var, Reporting and Resources Meeting',\n",
       " 'Var, Reporting and Resources Meeting',\n",
       " 'Westgate',\n",
       " 'Westgate',\n",
       " 'Meeting re: Storage Strategies in the West',\n",
       " 'Meeting re: Storage Strategies in the West',\n",
       " 'Re: Not business related..',\n",
       " 'Re: Original Sept check/closing',\n",
       " 'San Juan Index',\n",
       " 'Re: You Game?',\n",
       " 'San Juan Index',\n",
       " 'Investment Structure',\n",
       " 'Investment Structure',\n",
       " 'Re: Pick your Poison?',\n",
       " 'Investment Structure',\n",
       " 'Investment Structure',\n",
       " 'Gas Trading Vision mtg.',\n",
       " 'Re: Gas Trading Vision meeting',\n",
       " 'Gas Physical/Financial Position',\n",
       " 'Gas Physical/Financial Position',\n",
       " 'closing',\n",
       " 'closing',\n",
       " 'Re: Hello',\n",
       " 'Re: Hello',\n",
       " 'Re: PRC review - phone calls',\n",
       " 'Re: Associates & Analysts Eligible for Promotion',\n",
       " 'Westgate Proforma-Phillip Allen.xls',\n",
       " 'Westgate Proforma-Phillip Allen.xls',\n",
       " 'Re: burnet',\n",
       " 'Re: Sept 1 Payment',\n",
       " 'Re: Court Ordered Notice to Customers and Registered Users of',\n",
       " 'Contact list for mid market',\n",
       " 'Contact list for mid market',\n",
       " 'Westgate Proforma-Phillip Allen.xls',\n",
       " 'Westgate Proforma-Phillip Allen.xls',\n",
       " 'Re: Chelsea Villas',\n",
       " 'Re: VaR by Curve',\n",
       " 'Re: Sagewood etc.',\n",
       " 'Sagewood Town Homes',\n",
       " 'Sagewood Town Homes',\n",
       " 'Westgate Proforma-Phillip Allen.xls',\n",
       " 'Westgate Proforma-Phillip Allen.xls',\n",
       " 'RE: Additional properties in San Antonio',\n",
       " 'Additional properties in San Antonio',\n",
       " 'FW: charts',\n",
       " 'charts',\n",
       " 'RE: A&A to be placed',\n",
       " 'A&A to be placed',\n",
       " 'RE: The Stage',\n",
       " 'The Stage',\n",
       " 'RE: West Gas Headcount',\n",
       " 'West Gas Headcount',\n",
       " \"RE: Bishop's Corner Foundation Engineer Information\",\n",
       " \"Bishop's Corner Foundation Engineer Information\",\n",
       " 'Texas1031_homepage',\n",
       " 'FW: charts',\n",
       " 'charts',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE: El Paso Merchant Comments on Reporting Requirements',\n",
       " 'El Paso Merchant Comments on Reporting Requirements',\n",
       " 'RE: Call to Discuss Possible Options to Mitigate Effect of DWR',\n",
       " 'Call to Discuss Possible Options to Mitigate Effect of DWR Contracts--Privileged and Confidential',\n",
       " 'FW: Bishops Corner',\n",
       " 'Bishops Corner',\n",
       " 'FW: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'FW: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'FW: charts',\n",
       " 'charts',\n",
       " 'FW: NEWGen June Release',\n",
       " 'NEWGen June Release',\n",
       " 'RE: Do you want me to take you off my e-mail distribution list?',\n",
       " 'Do you want me to take you off my e-mail distribution list?',\n",
       " 'RE: Meeting to discuss West gas desk \"FERC messages\"',\n",
       " 'Meeting to discuss West gas desk \"FERC messages\"',\n",
       " 'RE: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'RE: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'FW: Crossroads Storage Project',\n",
       " 'FW: Crossroads Storage Project',\n",
       " 'Crossroads Storage Project',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'FW: Meeting to discuss West gas desk \"FERC messages\"',\n",
       " 'RE: Meeting to discuss West gas desk \"FERC messages\"',\n",
       " 'RE: Meeting to discuss West gas desk \"FERC messages\"',\n",
       " 'Meeting to discuss West gas desk \"FERC messages\"',\n",
       " 'RE: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'RE: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'FW:',\n",
       " 'RE:',\n",
       " 'RE: no e-mai',\n",
       " 'no e-mai',\n",
       " 'FW:',\n",
       " 'Re:',\n",
       " 'FW: The Stage',\n",
       " 'The Stage',\n",
       " 'FW: Goldman Comment re: Enron issued this morning - Revised Price',\n",
       " 'Goldman Comment re: Enron issued this morning - Revised Price Target of $68/share',\n",
       " 'RE: FW: The Stage',\n",
       " 'Re: FW: The Stage',\n",
       " 'FW: California gas intrastate matters',\n",
       " 'California gas intrastate matters',\n",
       " 'FW: El Paso Announces Binding Open Season for Additional Capacity',\n",
       " 'El Paso Announces Binding Open Season for Additional Capacity on Line 2000',\n",
       " 'El Paso Announces Binding Open Season for Additional Capacity\\ton Line 2000',\n",
       " 'FW: California gas intrastate matters - July 11 conference call',\n",
       " 'California gas intrastate matters - July 11 conference call',\n",
       " 'California gas intrastate matters',\n",
       " 'FW: West Power Strategy Briefing',\n",
       " 'West Power Strategy Briefing',\n",
       " 'RE:',\n",
       " 'FW:',\n",
       " 'FW: Party',\n",
       " 'Party',\n",
       " 'RE: CA Instrate Gas matters',\n",
       " 'CA Instrate Gas matters',\n",
       " 'FW: CA Instrate Gas matters',\n",
       " 'CA Instrate Gas matters',\n",
       " 'RE: Analyst/Associate Program: 2 Minutes of Your Time',\n",
       " 'Analyst/Associate Program: 2 Minutes of Your Time',\n",
       " 'FW: American Express Letter',\n",
       " 'American Express Letter',\n",
       " 'RE: Party',\n",
       " 'Party',\n",
       " 'FW: Party',\n",
       " 'RE: Party',\n",
       " 'RE: Party',\n",
       " 'FW: report',\n",
       " 'report',\n",
       " 'RE: simulation environment',\n",
       " 'simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'simulation environment',\n",
       " 'FW: Western Strategy Session',\n",
       " 'Western Strategy Session',\n",
       " 'RE: simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'RE: simulation environment',\n",
       " 'simulation environment',\n",
       " 'FW: Complaint Against El Paso',\n",
       " '=09Complaint Against El Paso',\n",
       " '=09Complaint Against El Paso',\n",
       " 'FW: Western Strategy Session',\n",
       " 'Western Strategy Session',\n",
       " \"RE: Bishop's Corner, Forms\",\n",
       " 'FW: West Position',\n",
       " 'West Position',\n",
       " 'FW: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'FW: Action Requested:  Past Due Invoice',\n",
       " 'Action Requested:  Past Due Invoice',\n",
       " 'FW: Meet your New Analyst(s)',\n",
       " 'Meet your New Analyst(s)',\n",
       " 'RE: West Position',\n",
       " 'West Position',\n",
       " 'FW: El Paso Update 7/23/011',\n",
       " 'El Paso Update 7/23/011',\n",
       " 'FW: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'RE: Questar',\n",
       " 'Questar',\n",
       " 'FW: NGI access to eol',\n",
       " 'Re: NGI access to eol',\n",
       " 'RE: NGI access to eol',\n",
       " 'Re: NGI access to eol',\n",
       " 'FW: FERC Order on Reporting CA gas sales',\n",
       " '=09FERC Order on Reporting CA gas sales',\n",
       " '=09FERC Order on Reporting CA gas sales',\n",
       " 'FW: Mid C New deals Sept 24',\n",
       " 'Mid C New deals Sept 24',\n",
       " 'RE:',\n",
       " 'Re:',\n",
       " 'FW: Promotion Approval',\n",
       " 'Promotion Approval',\n",
       " 'RE:',\n",
       " 'Re:',\n",
       " \"Ellie's status\",\n",
       " 'Re:',\n",
       " 'FW: Deal Fixed Price Report - In an Excel format',\n",
       " 'Deal Fixed Price Report - In an Excel format',\n",
       " \"FW: Enron' s August Baseload Physical Fixed Price Transactions as\",\n",
       " \"FW: Enron' s August Baseload Physical Fixed Price Transactions as of 07/27/01\",\n",
       " \"Enron' s August Baseload Physical Fixed Price Transactions as of 07/27/01\",\n",
       " \"FW: Enron' s August Baseload Physical Fixed Price Transactions as\",\n",
       " \"FW: Enron' s August Baseload Physical Fixed Price Transactions as of 07/27/01\",\n",
       " \"Enron' s August Baseload Physical Fixed Price Transactions as of 07/27/01\",\n",
       " 'FW:',\n",
       " 'FW: Action Requested:  Past Due Invoice',\n",
       " 'Action Requested:  Past Due Invoice',\n",
       " \"FW: Bishop's Corner\",\n",
       " \"Bishop's Corner\",\n",
       " 'Forbes.com story',\n",
       " 'FW: Utility Construction Escrow Agreement (Allen/AMHP)',\n",
       " 'Utility Construction Escrow Agreement (Allen/AMHP)',\n",
       " 'FW: First Amendment to Contract (Allen/AMHP)',\n",
       " 'First Amendment to Contract (Allen/AMHP)',\n",
       " 'RE: Message from John and Louise - Enron Americas Management',\n",
       " '=09Message from John and Louise - Enron Americas Management Offsite',\n",
       " 'RE:',\n",
       " 'Re:',\n",
       " 'RE: Answer',\n",
       " 'Answer',\n",
       " 'RE: West Position',\n",
       " 'FW: West Position',\n",
       " 'RE: West Position',\n",
       " 'West Position',\n",
       " 'RE: Utility Construction Escrow Agreement (Allen/AMHP)',\n",
       " 'Utility Construction Escrow Agreement (Allen/AMHP)',\n",
       " 'FW: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " 'RE: Western Wholesale Activities - Gas & Power Conf. Call Privileged & Confidential Communication Attorney-Client Communication and Attorney Work Product Privileges Asserted',\n",
       " 'RE: Message from John and Louise - Enron Americas Management',\n",
       " '=09RE: Message from John and Louise - Enron Americas Management Off=',\n",
       " '=09Message from John and Louise - Enron Americas Management Offsite',\n",
       " 'RE: Management Offsite Video Meetings',\n",
       " 'FW: Management Offsite Video Meetings',\n",
       " 'Management Offsite Video Meetings',\n",
       " 'RE: Basic Risk Management (BRM) Simulation Deal with Accenture',\n",
       " 'Basic Risk Management (BRM) Simulation Deal with Accenture',\n",
       " 'Simulation',\n",
       " 'RE: Special Warranty Deed/First Amendment to Contract - Lakeline',\n",
       " 'Special Warranty Deed/First Amendment to Contract - Lakeline Apts\\t.',\n",
       " 'FW:',\n",
       " 'RE: Attention Body Shop Members -- UPDATE on Body Shop Closure',\n",
       " 'Attention Body Shop Members -- UPDATE on Body Shop Closure',\n",
       " 'RE: Please read-PRC followup',\n",
       " 'Please read-PRC followup',\n",
       " 'RE: jobs on the gas desk',\n",
       " 'jobs on the gas desk',\n",
       " 'RE: Please Reply by Wednesday, 8/22 -- Draft Rehearing Request --',\n",
       " 'Please Reply by Wednesday, 8/22 -- Draft Rehearing Request -- FERC Reporting Requirements for California Sales',\n",
       " 'RE:',\n",
       " 'FW:',\n",
       " 'FW: Curve Shift File',\n",
       " 'Curve Shift File',\n",
       " 'RE:',\n",
       " 'FW:',\n",
       " 'FW: El Paso 1110',\n",
       " 'El Paso 1110',\n",
       " 'RE: Bishops Corner',\n",
       " 'Bishops Corner',\n",
       " 'FW: Enron Center Garage',\n",
       " 'Enron Center Garage',\n",
       " 'FW: Nine Energy Services',\n",
       " 'RE: Nine Energy Services',\n",
       " 'Nine Energy Services',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'FW:',\n",
       " 'FW: Wildflower, Rayburn, Emilie apts',\n",
       " 'FW: Wildflower, Rayburn, Emilie apts',\n",
       " 'RE: FW:',\n",
       " 'Re: FW:',\n",
       " 'RE: Bike Commute',\n",
       " 'Bike Commute',\n",
       " 'RE: Simulation Common Mistakes',\n",
       " 'Simulation Common Mistakes',\n",
       " 'RE:',\n",
       " 'Re:',\n",
       " 'RE: Outing Event on Ultra Sailing Yacht set up for Enron/Accenture',\n",
       " 'Outing Event on Ultra Sailing Yacht set up for Enron/Accenture BRM Initiative Team (directions and map attached)',\n",
       " 'RE: Current Schedule as of 3 pm on Monday',\n",
       " 'Current Schedule as of 3 pm on Monday',\n",
       " 'FW: Competitive Analysis Update #4- US Terrorism Attacks',\n",
       " 'Competitive Analysis Update #4- US Terrorism Attacks',\n",
       " 'FW:',\n",
       " 'RE: Leander etc.',\n",
       " 'Leander etc.',\n",
       " 'FW: Marketer Support of Generator Motion on Credit Issues',\n",
       " 'RE: Marketer Support of Generator Motion on Credit Issues',\n",
       " 'RE: Marketer Support of Generator Motion on Credit Issues',\n",
       " 'RE: Marketer Support of Generator Motion on Credit Issues',\n",
       " 'Fwd: Marketer Support of Generator Motion on Credit Issues',\n",
       " 'Marketer Support of Generator Motion on Credit Issues',\n",
       " 'RE:',\n",
       " 'FW: Nine Energy Services',\n",
       " 'Nine Energy Services',\n",
       " 'RE: howdy!!',\n",
       " 'howdy!!',\n",
       " 'RE: howdy!!',\n",
       " 'howdy!!',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'FW:',\n",
       " 'FW:',\n",
       " 'FW: Action Requested:  Past Due Invoice',\n",
       " 'Action Requested:  Past Due Invoice',\n",
       " 'FW: Action Requested:  Past Due Invoice',\n",
       " 'Action Requested:  Past Due Invoice',\n",
       " 'FW: El Paso Capacity',\n",
       " 'El Paso Capacity',\n",
       " 'RE: Final Internal Review for Sign Off: Common Mistakes',\n",
       " 'Final Internal Review for Sign Off: Common Mistakes',\n",
       " 'RE: Final Internal Review for Sign Off: Performance Objectives',\n",
       " 'Final Internal Review for Sign Off: Performance Objectives',\n",
       " 'RE: Final Internal Review for Sign Off: Topics and Related',\n",
       " 'Final Internal Review for Sign Off: Topics and Related Objectives',\n",
       " 'FW: Arizona',\n",
       " 'Arizona',\n",
       " 'FW: El Paso Capacity',\n",
       " 'El Paso Capacity',\n",
       " 'RE: Comanch Trace Home',\n",
       " 'Comanch Trace Home',\n",
       " 'RE: Log Home Site',\n",
       " 'Log Home Site',\n",
       " 'RE: Bishops',\n",
       " '=09Bishops',\n",
       " 'RE: Topic Outlines',\n",
       " 'Topic Outlines',\n",
       " 'RE: workout',\n",
       " 'workout',\n",
       " 'RE: Managing Directors Meeting',\n",
       " 'Managing Directors Meeting',\n",
       " 'RE: Paul Margraves Meeting',\n",
       " 'Paul Margraves Meeting',\n",
       " 'FW:',\n",
       " 'RE:',\n",
       " 'RE: Huntley followup question',\n",
       " 'Huntley followup question',\n",
       " 'RE: Check this out -',\n",
       " 'Check this out -',\n",
       " 'RE: kerrville',\n",
       " 'kerrville',\n",
       " 'RE: Huntley update',\n",
       " 'Huntley update',\n",
       " 'RE: Huntley followup question',\n",
       " 'FW: FERC Special Meetings on Friday 10/26/01 and Monday 10/29/01',\n",
       " 'FERC Special Meetings on Friday 10/26/01 and Monday 10/29/01',\n",
       " 'FW: Distribution Form',\n",
       " 'Distribution Form',\n",
       " 'RE: Huntley/question',\n",
       " 'Huntley/question',\n",
       " 'RE: Distribution Form',\n",
       " 'Distribution Form',\n",
       " 'RE: Distribution Form',\n",
       " 'RE: Distribution Form',\n",
       " 'RE: Distribution Form',\n",
       " 'Distribution Form',\n",
       " 'RE: Topic Framework Deliverable - Sign-Off for Acceptance',\n",
       " 'Topic Framework Deliverable - Sign-Off for Acceptance',\n",
       " 'Topic Framework Deliverable - Sign-Off for Acceptance',\n",
       " 'Topic Framework Updates!',\n",
       " 'Topic Frameworks - Updates Completed',\n",
       " 'RE: Blackline of First Amendment to Contract',\n",
       " 'Blackline of First Amendment to Contract',\n",
       " 'FW: Zero Option',\n",
       " 'Zero Option',\n",
       " 'RE: BRM Case & Options',\n",
       " 'BRM Case & Options',\n",
       " 'FW: Blackline of First Amendment to Contract',\n",
       " 'RE: Blackline of First Amendment to Contract',\n",
       " 'Blackline of First Amendment to Contract',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'the candidate we spoke about this morning...',\n",
       " 'RE: Confirmation: Risk Management Simulation Meeting 10/30/01',\n",
       " 'Confirmation: Risk Management Simulation Meeting 10/30/01',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'the candidate we spoke about this morning...',\n",
       " 'RE: Confirmation: Risk Management Simulation Meeting 10/30/01',\n",
       " 'RE: Confirmation: Risk Management Simulation Meeting 10/30/01',\n",
       " 'RE: Bishops Corner',\n",
       " 'Bishops Corner',\n",
       " 'FW: Properties for sale',\n",
       " 'Properties for sale',\n",
       " 'FW: Chase Backtest',\n",
       " 'FW: Chase Backtest',\n",
       " 'RE: try this one for starters',\n",
       " 'FW: try this one for starters',\n",
       " 'RE: Distribution of report',\n",
       " '=09Distribution of report',\n",
       " 'RE: Huntley/question',\n",
       " 'Re: Huntley/question',\n",
       " 'RE: Huntley/question',\n",
       " 'Re: 2- SURVEY/INFORMATION EMAIL 5-14- 01',\n",
       " '=092- SURVEY/INFORMATION EMAIL 5-14- 01',\n",
       " 'RE: Amerex - Scott Halprian',\n",
       " 'Amerex - Scott Halprian',\n",
       " 'FW: November 2001 FERC Open and Special Meeting Notice',\n",
       " 'November 2001 FERC Open and Special Meeting Notice',\n",
       " 'Texas1031_homepage',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE: Exchange Documents',\n",
       " 'Exchange Documents',\n",
       " 'RE: Huntley/question',\n",
       " 'Re: Huntley/question',\n",
       " 'RE: Huntley/question',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'FW: Phantom Stock Payouts',\n",
       " 'Phantom Stock Payouts',\n",
       " 'RE: Interface Design Update',\n",
       " 'Interface Design Update',\n",
       " 'RE: new PO available',\n",
       " 'new PO available',\n",
       " 'RE: word file as promised',\n",
       " 'word file as promised',\n",
       " 'FW:',\n",
       " 'RE:',\n",
       " 'RE: Muni Bond Ladder',\n",
       " 'Muni Bond Ladder',\n",
       " 'RE:',\n",
       " 'RE: Home Nortel VPN use',\n",
       " 'Home Nortel VPN use',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE:',\n",
       " 'RE: word file as promised',\n",
       " '=09word file as promised',\n",
       " 'RE: Muni Proposal',\n",
       " 'Muni Proposal',\n",
       " 'RE: Thursday Meeting',\n",
       " 'Thursday Meeting',\n",
       " 'RE: new PO available',\n",
       " 'Re: new PO available',\n",
       " 'Re:',\n",
       " 'FW:',\n",
       " 'FW:',\n",
       " 'RE: BRM Case & Options',\n",
       " 'BRM Case & Options',\n",
       " 'FW:',\n",
       " \"RE: Summary of Today's Meeting\",\n",
       " \"Summary of Today's Meeting\",\n",
       " 'RE: PO spreadsheets',\n",
       " 'PO spreadsheets',\n",
       " 'California Summary',\n",
       " 'California Summary',\n",
       " 'Additional California Load Information',\n",
       " 'Re: Western Wholesale Activities - Gas & Power Conf. Call',\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = [x.strip() for x in open(\"enronsubjects.txt\").readlines()]\n",
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check whether or not a pattern matches a given string in Python with the `re.search()` function. The first parameter to search is the regular expression you're trying to match; the second parameter is the string you're matching against.\n",
    "\n",
    "Here's an example, using a very simple regular expression. The following code prints out only those lines in our Enron corpus that match the (very simple) regular expression `shipping`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FW: How to use UPS for shipping on the internet',\n",
       " 'FW: How to use UPS for shipping on the internet',\n",
       " 'How to use UPS for shipping on the internet',\n",
       " 'FW: How to use UPS for shipping on the internet',\n",
       " 'FW: How to use UPS for shipping on the internet',\n",
       " 'How to use UPS for shipping on the internet',\n",
       " 'lng shipping/mosk meeting in tokyo 2nd of feb',\n",
       " 'lng shipping/mosk meeting in tokyo 2nd of feb',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'lng shipping',\n",
       " 'lng shipping',\n",
       " 'lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'lng shipping']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[line for line in subjects if re.search(\"shipping\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its simplest, a regular expression matches a string if that string contains exactly the characters you've specified in the regular expression. So the expression `shipping` matches strings that contain exactly the sequences of `s`, `h`, `i`, `p`, `p`, `i`, `n`, and `g` in a row. If the regular expression matches, `re.search()` evaluates to `True` and the matching line is included in the evaluation of the list comprehension.\n",
    "\n",
    "> BONUS TECH TIP: `re.search()` doesn't actually evaluate to `True` or `False`---it evaluates to either a `Match` object if a match is found, or `None` if no match was found. Those two count as `True` and `False` for the purposes of an `if` statement, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Metacharacters: character classes\n",
    "\n",
    "The \"shipping\" example is pretty boring. (There was hardly any fan fiction in there at all.) Let's go a bit deeper into detail with what you can do with regular expressions. There are certain characters or strings of characters that we can insert into a regular expressions that have special meaning. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FW: How to use UPS for shipping on the internet',\n",
       " 'FW: How to use UPS for shipping on the internet',\n",
       " 'How to use UPS for shipping on the internet',\n",
       " 'FW: How to use UPS for shipping on the internet',\n",
       " 'FW: How to use UPS for shipping on the internet',\n",
       " 'How to use UPS for shipping on the internet',\n",
       " \"FW: We've been shopping!\",\n",
       " 'Re: Start shopping...',\n",
       " 'Start shopping...',\n",
       " 'lng shipping/mosk meeting in tokyo 2nd of feb',\n",
       " 'lng shipping/mosk meeting in tokyo 2nd of feb',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'lng shipping',\n",
       " 'lng shipping',\n",
       " 'lng shipping',\n",
       " 'Re: lng shipping',\n",
       " 'lng shipping',\n",
       " 'FW: Online shopping',\n",
       " 'Online shopping']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(\"sh.pping\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a regular expression, the character `.` means \"match any character here.\" So, using the regular expression `sh.pping`, we get lines that match `shipping` but also `shopping`. The `.` is an example of a regular expression *metacharacter*---a character (or string of characters) that has a special meaning.\n",
    "\n",
    "Here are a few more metacharacters. These metacharacters allow you to say that a character belonging to a particular *class* of characters should be matched in a particular position:\n",
    "\n",
    "| metacharacter | meaning |\n",
    "|---------------|---------|\n",
    "| `.` | match any character |\n",
    "| `\\w` | match any alphanumeric (\"*w*ord\") character (lowercase and capital letters, 0 through 9, underscore) |\n",
    "| `\\s` | match any whitespace character (i.e., space and tab) |\n",
    "| `\\S` | match any non-whitespace character (the inverse of \\s) |\n",
    "| `\\d` | match any digit (0 through 9) |\n",
    "| `\\.` | match a literal `.` |\n",
    "\n",
    "Here, for example, is a (clearly imperfect) regular expression to search for all subject lines containing a time of day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RE: 3:17pm',\n",
       " '3:17pm',\n",
       " \"RE: It's On!!! - 2:00pm Today\",\n",
       " \"FW: It's On!!! - 2:00pm Today\",\n",
       " \"It's On!!! - 2:00pm Today\",\n",
       " 'Re: Registration Confirmation: Larry Summers on 12/6 at 1:45pm (was',\n",
       " 'Re: Conference Call today 2/9/01 at 11:15am PST',\n",
       " 'Conference Call today 2/9/01 at 11:15am PST',\n",
       " '5/24 1:00pm conference call.',\n",
       " '5/24 1:00pm conference call.',\n",
       " 'FW: 07:33am EDT 15-Aug-01 Prudential Securities (C',\n",
       " 'FW: 07:33am EDT 15-Aug-01 Prudential Securities (C',\n",
       " '07:33am EDT 15-Aug-01 Prudential Securities (C',\n",
       " \"Re: Updated Mar'00 Requirements Received at 11:25am from CES\",\n",
       " \"Re: Updated Mar'00 Requirements Received at 11:25am from CES\",\n",
       " \"Re: Updated Mar'00 Requirements Received at 11:25am from CES\",\n",
       " \"Updated Mar'00 Requirements Received at 11:25am from CES\",\n",
       " 'Reminder: Legal Team Meeting -- Friday, 9:00am Houston time',\n",
       " 'Thursday, March 7th 1:30-3:00pm: REORIENTATION',\n",
       " 'Meeting at 2:00pm Friday',\n",
       " 'Meeting at 2:00pm Friday',\n",
       " 'Fw: 12:30pm Deadline for changes to letters or contracts today',\n",
       " '12:30pm Deadline for changes to letters or contracts today',\n",
       " 'Johnathan actually resigned at 9:00am this morning',\n",
       " 'FW: Enron Conference Call Today, 11:00am CST',\n",
       " 'Enron Conference Call Today, 11:00am CST',\n",
       " 'Meeting, Wednesday, January 23 at 10:00am at the Houstonian',\n",
       " 'RE: TVA Meeting, Wednesday June13, 1:15pm, EB3125b',\n",
       " 'TVA Meeting, Wednesday June13, 1:15pm, EB3125b',\n",
       " 'Re: Dabhol Update: Conference Call Thursday, Dec. 28, 8:00am',\n",
       " 'Dabhol Update: Conference Call Thursday, Dec. 28, 8:00am Houston time',\n",
       " 'FW: Victoria Ashley Jones Born 5/25/01 7:31am.',\n",
       " 'Fw: Victoria Ashley Jones Born 5/25/01 7:31am.',\n",
       " 'Victoria Ashley Jones Born 5/25/01 7:31am.',\n",
       " 'RE: Victoria Ashley Jones Born 5/25/01 7:31am.',\n",
       " 'Fw: Victoria Ashley Jones Born 5/25/01 7:31am.',\n",
       " 'Victoria Ashley Jones Born 5/25/01 7:31am.',\n",
       " 'RE: UCSF Cogen Calculation Conf Call, 10/12/01 at 8:00am PST',\n",
       " 'UCSF Cogen Calculation Conf Call, 10/12/01 at 8:00am PST',\n",
       " 'FW: Confirmation:  UCSF Cogen Conf Call. 10/22/02 at 8:00am',\n",
       " '=09RE: Confirmation:  UCSF Cogen Conf Call. 10/22/02 at 8:00am PST/=',\n",
       " '=09Confirmation:  UCSF Cogen Conf Call. 10/22/02 at 8:00am PST/10:0=',\n",
       " 'RE: Confirmation:  UCSF Cogen Conf Call. 10/22/02 at 8:00am',\n",
       " '=09Confirmation:  UCSF Cogen Conf Call. 10/22/02 at 8:00am PST/10:0=',\n",
       " 'Re: March expenses - deadline 04-04-01 2:00pm',\n",
       " 'Cirque - Jan 24 5:00pm show']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"\\d:\\d\\d\\wm\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's that regular expression again: `r\"\\d:\\d\\d\\wm\"`. I'm going to show you how to read this, one unit at a time.\n",
    "\n",
    "\"Hey, regular expression engine. Tell me if you can find this pattern in the current string. First of all, look for any number (`\\d`). If you find that, look for a colon right after it (`:`). If you find that, look for another number right after it (`\\d`). If you find *that*, look for any alphanumeric character---you know, a letter, a number, an underscore. If you find  that, then look for a `m`. Good? If you found all of those things in a row, then the pattern matched.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####But what about that weirdo `r\"\"`?\n",
    "\n",
    "Python provides another way to include string literals in your program, in addition to the single- and double-quoted strings we've already discussed. The r\"\" string literal, or \"raw\" string, includes all characters inside the quotes literally, without interpolating special escape characters. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is\n",
      "a test\n",
      "this is\\na test\n",
      "I love \\ backslashes!\n",
      "I love \\ backslashes!\n"
     ]
    }
   ],
   "source": [
    "print \"this is\\na test\"\n",
    "print r\"this is\\na test\"\n",
    "print \"I love \\\\ backslashes!\"\n",
    "print r\"I love \\ backslashes!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, whereas a double- or single-quoted string literal interprets `\\n` as a new line character, the raw quoted string includes those characters as they were literally written. More importantly, for our purposes at least, is the fact that, in the raw quoted string, we only need to write one backslash in order to get a literal backslash in our string.\n",
    "\n",
    "Why is this important? Because regular expressions use backslashes all the time, and we don't want Python to try to interpret those backslashes as special characters. (Inside a regular string, we'd have to write a simple regular expression like `\\b\\w+\\b` as `\\\\b\\\\w+\\\\b`---yecch.)\n",
    "\n",
    "So the basic rule of thumb is this: use r\"\" to quote any regular expressions in your program. All of the examples you'll see below will use this convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Character classes in-depth\n",
    "\n",
    "You can define your own character classes by enclosing a list of characters, or range of characters, inside square brackets:\n",
    "\n",
    "| regex | explanation |\n",
    "|-------|-------------|\n",
    "| `[aeiou]` | matches any vowel |\n",
    "| `[02468]` | matches any even digit |\n",
    "| `[a-z]` | matches any lower-case letter |\n",
    "| `[A-Z]` | matches any upper-case character |\n",
    "| `[^0-9]` | matches any non-digit (the ^ inverts the class, matches anything not in the list) |\n",
    "| `[Ee]` | matches either `E` or `e` |\n",
    "\n",
    "Let's find every subject line where we have four or more vowels in a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Re: Natural gas quote for Louiisiana-Pacific (L-P)',\n",
       " 'WooooooHoooooo more Vacation',\n",
       " 'Re: Clickpaper Counterparties waiting to clear the work queue',\n",
       " 'Gooooooooooood Bye!',\n",
       " 'Gooooooooooood Bye!',\n",
       " 'RE: Hello Sweeeeetie',\n",
       " 'Hello Sweeeeetie',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'Re: FW: Wasss Uuuuuup STG?',\n",
       " 'RE: Rrrrrrrooooolllllllllllll TIDE!!!!!!!!',\n",
       " 'Rrrrrrrooooolllllllllllll TIDE!!!!!!!!',\n",
       " 'FW: The Osama Bin Laden Song ( Soooo Funny !! )',\n",
       " 'Fw: The Osama Bin Laden Song ( Soooo Funny !! )',\n",
       " 'The Osama Bin Laden Song ( Soooo Funny !! )',\n",
       " 'RE: duuuuhhhhh',\n",
       " 'RE: duuuuhhhhh',\n",
       " 'RE: duuuuhhhhh',\n",
       " 'duuuuhhhhh',\n",
       " 'RE: duuuuhhhhh',\n",
       " 'duuuuhhhhh',\n",
       " 'RE: FPL Queue positions 1-15',\n",
       " 'Re: FPL Queue positions 1-15',\n",
       " 'Re: Helloooooo!!!',\n",
       " 'Re: Helloooooo!!!',\n",
       " 'Fw: FW: OOOooooops',\n",
       " 'FW: FW: OOOooooops',\n",
       " 'Re: yeeeeha',\n",
       " 'yeeeeha',\n",
       " 'yahoooooooooooooooooooo',\n",
       " 'RE: yahoooooooooooooooooooo',\n",
       " 'RE: yahoooooooooooooooooooo',\n",
       " 'yahoooooooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " \"FW: duuuuuuuuuuuuuuuuude...........what's up?\",\n",
       " \"RE: duuuuuuuuuuuuuuuuude...........what's up?\",\n",
       " \"RE: duuuuuuuuuuuuuuuuude...........what's up?\",\n",
       " 'Re: skiiiiiiiiing',\n",
       " 'skiiiiiiiiing',\n",
       " 'scuba dooooooooooooo',\n",
       " 'RE: scuba dooooooooooooo',\n",
       " 'RE: scuba dooooooooooooo',\n",
       " 'scuba dooooooooooooo',\n",
       " 'Re: skiiiiiiiing',\n",
       " 'skiiiiiiiing',\n",
       " 'Re: skiiiiiiiing',\n",
       " 'Re: skiiiiiiiiing',\n",
       " \"RE: Clickpaper CP's awaiting migration in work queue's 06/27/01\",\n",
       " \"FW: Clickpaper CP's awaiting migration in work queue's 06/27/01\",\n",
       " \"Clickpaper CP's awaiting migration in work queue's 06/27/01\",\n",
       " 'RE:  Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'FW: Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'Re: FW: Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'FW: Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'FW: Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'Fw: Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'Sequoia Adv. Pro.: Draft Stipulation and Order',\n",
       " 'i would have done this but i was toooo busy.....']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"[aeiou][aeiou][aeiou][aeiou]\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Metacharacters: anchors\n",
    "\n",
    "The next important kind of metacharacter is the *anchor*. An anchor doesn't match a character, but matches a particular place in a string.\n",
    "\n",
    "| anchor | meaning |\n",
    "|--------|---------|\n",
    "| `^` | match at beginning of string |\n",
    "| `$` | match at end of string |\n",
    "| `\\b` | match at word boundary |\n",
    "\n",
    "> Note: `^` in a character class has a different meaning from `^` outside a character class!\n",
    "\n",
    "> Note #2: If you want to search for a literal dollar sign (`$`), you need to put a backslash in front of it, like so: `\\$`\n",
    "\n",
    "Now we have enough regular expression knowledge to do some fairly sophisticated matching. As an example, all the subject lines that begin with the string `New York`, regardless of whether or not the initial letters were capitalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York Details',\n",
       " 'New York Power Authority',\n",
       " 'New York Power Authority',\n",
       " 'New York Power Authority',\n",
       " 'New York Power Authority',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'New York, etc.',\n",
       " 'New York, etc.',\n",
       " 'New York sites',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'New York City Marathon Guaranteed Entry',\n",
       " 'new york rest reviews',\n",
       " 'New York State Electric & Gas Corporation (\"NYSEG\")',\n",
       " 'New York State Electric & Gas Corporation (\"NYSEG\")',\n",
       " 'New York State Electric & Gas Corporation (\"NYSEG\")',\n",
       " 'New York State Electric & Gas (\"NYSEG\")',\n",
       " 'New York regulatory restriccions',\n",
       " 'New York regulatory restriccions',\n",
       " 'New York Bar Numbers']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"^[Nn]ew [Yy]ork\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every subject line that ends with an ellipsis (there are a lot of these, so I'm only displaying the first 30):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Re: Inquiry....',\n",
       " 'Re: Inquiry....',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'RE: the candidate we spoke about this morning...',\n",
       " 'the candidate we spoke about this morning...',\n",
       " 'Re: Hmmmmm........',\n",
       " 'Hmmmmm........',\n",
       " 'FW: Bumping into the husband....',\n",
       " 'FW: Bumping into the husband....',\n",
       " 'RE: try this one...',\n",
       " 'RE: try this one...',\n",
       " 'Re: try this one...',\n",
       " 'try this one...',\n",
       " 'RE: try this one...',\n",
       " 'RE: try this one...',\n",
       " 'Re: try this one...',\n",
       " 'try this one...',\n",
       " 'RE: try this one...',\n",
       " 'RE: try this one...',\n",
       " 'Re: try this one...',\n",
       " 'try this one...',\n",
       " 'RE: try this one...',\n",
       " 'RE: try this one...']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"\\.\\.\\.$\", line)][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thirty subject lines containing the word \"oil\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Re: PIRA Global Oil and Natural Outlooks- Save these dates.',\n",
       " 'PIRA Global Oil and Natural Outlooks- Save these dates.',\n",
       " 'Re: PIRA Global Oil and Natural Outlooks- Save these dates.',\n",
       " '=09PIRA Global Oil and Natural Outlooks- Save these dates.',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Cabot Oil & Gas Marketing Corp. - Amendment and Confirmations to',\n",
       " 'Cabot Oil & Gas Marketing Corp. - Amendment and Confirmations to',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Re: Cabot Oil & Gas Marketing Corp. - 9/99 production - price',\n",
       " 'Cabot Oil & Gas Marketing Corp. - Amendment and Confirmations to',\n",
       " 'Cabot Oil & Gas Marketing Corp. - Amendment and Confirmations to',\n",
       " 'EOTT Crude Oil Tanks',\n",
       " 'Re: Oil Skim + \"Bugs\"',\n",
       " 'Oil Skim + \"Bugs\"',\n",
       " 'Oil Release Incident',\n",
       " 'Oil Release Incident',\n",
       " 'Oil Release Incident',\n",
       " 'RE: Location of the 2002 Institute on Oil & Gas Law & Taxation --',\n",
       " 'Location of the 2002 Institute on Oil & Gas Law & Taxation -- February, 2002',\n",
       " 'RE: Location of the 2002 Institute on Oil & Gas Law & Taxation --',\n",
       " 'RE: Location of the 2002 Institute on Oil & Gas Law & Taxation -- February, 2002',\n",
       " 'RE: Location of the 2002 Institute on Oil & Gas Law & Taxation',\n",
       " 'B & J Gas and Oil']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"\\b[Oo]il\\b\", line)][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Metacharacters: quantifiers\n",
    "\n",
    "Above we had a regular expression that looked like this:\n",
    "\n",
    "    [aeiou][aeiou][aeiou][aeiou]\n",
    "    \n",
    "Typing out all of those things is kind of a pain. Fortunately, there’s a way to specify how many times to match a particular character, using quantifiers. These affect the character that immediately precede them:\n",
    "\n",
    "| quantifier | meaning |\n",
    "|------------|---------|\n",
    "| `{n}` | match exactly n times |\n",
    "| `{n,m}` | match at least n times, but no more than m times |\n",
    "| `{n,}` | match at least n times |\n",
    "| `+` | match at least once (same as {1,}) |\n",
    "| `*` | match zero or more times |\n",
    "| `?` | match one time or zero times |\n",
    "\n",
    "For example, here's an example of a regular expression that finds subjects that contain at least fifteen capital letters in a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONGRATULATIONS!',\n",
       " 'CONGRATULATIONS!',\n",
       " 'Re: FW: Fw: Fw: Fw: Fw: Fw: Fw: PLEEEEEEEEEEEEEEEASE READ!',\n",
       " 'ACCOMPLISHMENTS',\n",
       " 'ACCOMPLISHMENTS',\n",
       " 'Re: FW: FORM: BILATERAL CONFIDENTIALITY AGREEMENT',\n",
       " 'FORM: BILATERAL CONFIDENTIALITY AGREEMENT',\n",
       " 'Re: CONGRATULATIONS!',\n",
       " 'CONGRATULATIONS!',\n",
       " 'Re: ORDER ACKNOWLEDGEMENT',\n",
       " 'ORDER ACKNOWLEDGEMENT',\n",
       " 'RE: CONGRATULATIONS',\n",
       " 'RE: CONGRATULATIONS',\n",
       " 'Re: CONGRATULATIONS',\n",
       " 'CONGRATULATIONS',\n",
       " 'RE: CONGRATULATIONS',\n",
       " 'RE: CONGRATULATIONS',\n",
       " 'RE: CONGRATULATIONS',\n",
       " 'RE: CONGRATULATIONS',\n",
       " 'Re: CONGRATULATIONS',\n",
       " 'CONGRATULATIONS',\n",
       " 'Re: VEPCO INTERCONNECTION AGREEMENT',\n",
       " 'VEPCO INTERCONNECTION AGREEMENT',\n",
       " 'Re: VEPCO INTERCONNECTION AGREEMENT',\n",
       " 'Re: VEPCO INTERCONNECTION AGREEMENT',\n",
       " 'VEPCO INTERCONNECTION AGREEMENT',\n",
       " 'Re: CONGRATULATIONS !',\n",
       " 'FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'Re: FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'FW: WASSSAAAAAAAAAAAAAABI!',\n",
       " 'RE: NOOOOOOOOOOOOOOOO',\n",
       " 'NOOOOOOOOOOOOOOOO',\n",
       " 'RE: NOOOOOOOOOOOOOOOO',\n",
       " 'CONGRATULATIONS!!!!!!!!!!!!!',\n",
       " 'RE: CONGRATULATIONS!!!!!!!!!!!!!',\n",
       " 'Re: CONGRATULATIONS!!!!!!!!!!!!!',\n",
       " 'CONGRATULATIONS',\n",
       " 'Re: CONFIDENTIALITY/CONFLICTS ISSUES MEETING',\n",
       " 'CONFIDENTIALITY/CONFLICTS ISSUES MEETING',\n",
       " 'GOALS AND ACCOMPLISHMENTS',\n",
       " 'ACCOMPLISHMENTS',\n",
       " 'Re: CONGRATULATIONS!',\n",
       " 'RE: STANDARDIZATION OF TANKER FREIGHT WORDING',\n",
       " 'RE: STANDARDIZATION OF TANKER FREIGHT WORDING',\n",
       " 'Re: STANDARDIZATION OF TANKER FREIGHT WORDING',\n",
       " 'STANDARDIZATION OF TANKER FREIGHT WORDING',\n",
       " 'BRRRRRRRRRRRRRRRRRRRRR',\n",
       " 'Re: CONGRATULATIONS !!!',\n",
       " 'CONGRATULATIONS !!!',\n",
       " 'RE: Mtg. to discuss assignment of customers. Transmission list:  P/LEGAL/PROJECTNETCO/NETCOTRANSMISSION.XLS',\n",
       " 'RE: Mtg. to discuss assignment of customers. Transmission list:  P/LEGAL/PROJECTNETCO/NETCOTRANSMISSION.XLS',\n",
       " 'Mtg. to discuss assignment of customers. Transmission list:  P/LEGAL/PROJECTNETCO/NETCOTRANSMISSION.XLS',\n",
       " 'FW: NEW WEATHER SWAPS ON THE INTERCONTINENTAL EXCHANGE',\n",
       " 'NEW WEATHER SWAPS ON THE INTERCONTINENTAL EXCHANGE']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"[A-Z]{15,}\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines that contain five consecutive vowels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WooooooHoooooo more Vacation',\n",
       " 'Gooooooooooood Bye!',\n",
       " 'Gooooooooooood Bye!',\n",
       " 'RE: Hello Sweeeeetie',\n",
       " 'Hello Sweeeeetie',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'FW: Waaasssaaaaabi !',\n",
       " 'Re: FW: Wasss Uuuuuup STG?',\n",
       " 'RE: Rrrrrrrooooolllllllllllll TIDE!!!!!!!!',\n",
       " 'Rrrrrrrooooolllllllllllll TIDE!!!!!!!!',\n",
       " 'Re: Helloooooo!!!',\n",
       " 'Re: Helloooooo!!!',\n",
       " 'Fw: FW: OOOooooops',\n",
       " 'FW: FW: OOOooooops',\n",
       " 'yahoooooooooooooooooooo',\n",
       " 'RE: yahoooooooooooooooooooo',\n",
       " 'RE: yahoooooooooooooooooooo',\n",
       " 'yahoooooooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " 'RE: I hate yahooooooooooooooo',\n",
       " 'I hate yahooooooooooooooo',\n",
       " \"FW: duuuuuuuuuuuuuuuuude...........what's up?\",\n",
       " \"RE: duuuuuuuuuuuuuuuuude...........what's up?\",\n",
       " \"RE: duuuuuuuuuuuuuuuuude...........what's up?\",\n",
       " 'Re: skiiiiiiiiing',\n",
       " 'skiiiiiiiiing',\n",
       " 'scuba dooooooooooooo',\n",
       " 'RE: scuba dooooooooooooo',\n",
       " 'RE: scuba dooooooooooooo',\n",
       " 'scuba dooooooooooooo',\n",
       " 'Re: skiiiiiiiing',\n",
       " 'skiiiiiiiing',\n",
       " 'Re: skiiiiiiiing',\n",
       " 'Re: skiiiiiiiiing']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"[aeiou]{5}\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of lines that are e-mail forwards, regardless of whether the subject line begins with `Fw:`, `FW:`, `Fwd:` or `FWD:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20159"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([line for line in subjects if re.search(r\"^F[Ww]d?:\", line)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines that have the word `news` in them and end in an exclamation point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RE: Christmas Party News!',\n",
       " 'FW: Christmas Party News!',\n",
       " 'Christmas Party News!',\n",
       " 'Good News!',\n",
       " 'Good News--Twice!',\n",
       " 'Re: VERY Interesting News!',\n",
       " 'Great News!',\n",
       " 'Re: Great News!',\n",
       " 'News Flash!',\n",
       " 'RE: News Flash!',\n",
       " 'RE: News Flash!',\n",
       " 'News Flash!',\n",
       " 'RE: Good News!',\n",
       " 'RE: Good News!',\n",
       " 'RE: Good News!',\n",
       " 'RE: Good News!',\n",
       " 'Good News!',\n",
       " 'RE: Good News!!!',\n",
       " 'Good News!!!',\n",
       " 'RE: Big News!',\n",
       " 'Big News!',\n",
       " 'Individual.com - News From a Friend!',\n",
       " 'Individual.com - News From a Friend!',\n",
       " 'Re: Individual.com - News From a Friend!',\n",
       " 'RE: We need news!',\n",
       " '=09We need news!',\n",
       " 'RE: Big News!',\n",
       " 'FW: Big News!',\n",
       " 'RE: Big News!',\n",
       " 'FW: Big News!',\n",
       " 'Big News!',\n",
       " 'FW: NW Wine News- Eroica, Sineann, Bergstrom, Hamacher, And more!',\n",
       " '=09NW Wine News- Eroica, Sineann, Bergstrom, Hamacher, And more!',\n",
       " 'RE: Good News!!!',\n",
       " 'Good News!!!',\n",
       " 'Re: Big News!',\n",
       " 'Big News!',\n",
       " 'RE: Good  News!',\n",
       " 'Good  News!']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"\\b[Nn]ews\\b.*!$\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Metacharacters: alternation\n",
    "\n",
    "One final bit of regular expression syntax: alternation.\n",
    "\n",
    "* `(?:x|y)`: match either x or y\n",
    "* `(?:x|y|z)`: match x, y or z\n",
    "* etc.\n",
    "\n",
    "So for example, if you wanted to count every subject line that begins with either `Re:` or `Fwd:`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39901"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([line for line in subjects if re.search(r\"^(?:Re|Fwd):\", line)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every subject line that mentions kinds of cats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Re: FW: cat attack',\n",
       " 'Re: FW: cat attack',\n",
       " 'Re: FW: cat attack',\n",
       " 'Re: FW: cat attack',\n",
       " 'Fw: Cat clip',\n",
       " 'Fw: Cat clip',\n",
       " 'FW: Cat clip',\n",
       " 'Re: Amazing Kitten',\n",
       " 'RE: How To Tell Which Cat Ate Your Drugs',\n",
       " 'FW: How To Tell Which Cat Ate Your Drugs',\n",
       " 'FW: How To Tell Which Cat Ate Your Drugs',\n",
       " \"FW: Fw: A cat's tale\",\n",
       " \"Fwd: Fw: A cat's tale\",\n",
       " 'Kim lost her cat this morning',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'Fw: cat clip............',\n",
       " 'cat clip............',\n",
       " 'kitty',\n",
       " 'Diary of a Cat',\n",
       " 'Diary of a Cat',\n",
       " 'Diary of a Cat',\n",
       " 'Diary of a Cat',\n",
       " 'Diary of a Cat',\n",
       " 'RE: Cat show?',\n",
       " 'Cat show?',\n",
       " 'RE: Cat show?',\n",
       " 'RE: Cat show?',\n",
       " 'RE: Cat show?',\n",
       " 'Cat show?']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"\\b(?:[Cc]at|[Kk]itten|[Kk]itty)\\b\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Capturing what matches\n",
    "\n",
    "The `re.search()` function allows us to check to see *whether or not* a string matches a regular expression. Sometimes we want to find out not just if the string matches, but also to what, exactly, in the string matched. In other words, we want to *capture* whatever it was that matched.\n",
    "\n",
    "The easiest way to do this is with the `re.findall()` function, which takes a regular expression and a string to match it against, and returns a list of all parts of the string that the regular expression matched. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alpha', 'gamma', 'delta', 'theta']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print re.findall(r\"\\b\\w{5}\\b\", \"alpha beta gamma delta epsilon zeta eta theta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression above, `\\b\\w{5}\\b`, is a regular expression that means \"find me strings of five non-white space characters between word boundaries\"---in other words, find me five-letter words. The `re.findall()` method returns a list of strings---not just telling us whether or not the string matched, but which parts of the string matched.\n",
    "\n",
    "For the following `re.findall()` examples, we'll be operating on the entire file of subject lines as a single string, instead of using a list comprehension for individual subject lines. Here's how to read in the entire file as one string, instead of as a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_subjects = open(\"enronsubjects.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done that, let's write a regular expression that finds all domain names in the subject lines (displaying just the first thirty because the list is long):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enron.com',\n",
       " 'enron.com',\n",
       " 'enron.com',\n",
       " 'enron.com',\n",
       " 'enron.com',\n",
       " 'enron.com',\n",
       " 'enron.com',\n",
       " 'enron.com',\n",
       " 'Forbes.com',\n",
       " 'Cortlandtwines.com',\n",
       " 'Cortlandtwines.com',\n",
       " 'Match.com',\n",
       " 'Amazon.com',\n",
       " 'Amazon.com',\n",
       " 'Ticketmaster.com',\n",
       " 'Ticketmaster.com',\n",
       " 'Concierge.com',\n",
       " 'Concierge.com',\n",
       " 'har.com',\n",
       " 'har.com',\n",
       " 'HoustonChronicle.com',\n",
       " 'HoustonChronicle.com',\n",
       " 'har.com',\n",
       " 'har.com',\n",
       " 'har.com',\n",
       " 'har.com',\n",
       " 'har.com',\n",
       " 'har.com',\n",
       " 'Concierge.com',\n",
       " 'Concierge.com']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\b\\w+\\.(?:com|net|org)\", all_subjects)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time the string `New York` is found, along with the word that comes directly afterward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York Details',\n",
       " 'New York Details',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York Times',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York on',\n",
       " 'New York Times',\n",
       " 'New York Times',\n",
       " 'New York Times',\n",
       " 'New York Times',\n",
       " 'New York Times',\n",
       " 'New York Times',\n",
       " 'New York Times',\n",
       " 'New York City',\n",
       " 'New York City',\n",
       " 'New York City',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Power',\n",
       " 'New York Mercantile',\n",
       " 'New York Mercantile',\n",
       " 'New York Branch',\n",
       " 'New York City',\n",
       " 'New York Energy',\n",
       " 'New York Energy',\n",
       " 'New York Energy',\n",
       " 'New York Energy',\n",
       " 'New York Energy',\n",
       " 'New York sites',\n",
       " 'New York sites',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York Hotel',\n",
       " 'New York City',\n",
       " 'New York City',\n",
       " 'New York City',\n",
       " 'New York City',\n",
       " 'New York voice',\n",
       " 'New York State',\n",
       " 'New York State',\n",
       " 'New York State',\n",
       " 'New York State',\n",
       " 'New York State',\n",
       " 'New York State',\n",
       " 'New York Inc',\n",
       " 'New York Office',\n",
       " 'New York Office',\n",
       " 'New York regulatory',\n",
       " 'New York regulatory',\n",
       " 'New York regulatory',\n",
       " 'New York regulatory',\n",
       " 'New York Bar',\n",
       " 'New York Bar']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"New York \\b\\w+\\b\", all_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to bring things full-circle, everything that looks like a zip code, sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00003',\n",
       " '00010',\n",
       " '00010',\n",
       " '00458',\n",
       " '01003',\n",
       " '02177',\n",
       " '06716',\n",
       " '06736',\n",
       " '06736',\n",
       " '06752',\n",
       " '06752',\n",
       " '06752',\n",
       " '06752',\n",
       " '06752',\n",
       " '06980',\n",
       " '06980',\n",
       " '10000',\n",
       " '10000',\n",
       " '11111',\n",
       " '11111',\n",
       " '11111',\n",
       " '11111']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(re.findall(r\"\\b\\d{5}\\b\", all_subjects))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Full example: finding the dollar value of the Enron e-mail subject corpus\n",
    "\n",
    "Here's an example that combines our regular expression prowess with our ability to do smaller manipulations on strings. We want to find all dollar amounts in the subject lines, and then figure out what their sum is.\n",
    "\n",
    "To understand what we're working with, let's start by writing a list comprehension that finds strings that just have the dollar sign (`$`) in them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Re: APEA - $228,204 hit',\n",
       " 'Re: APEA - $228,204 hit',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'DJ Cal-ISO Pays $10M To Avoid Rolling Blackouts Wed -Sources, DJ',\n",
       " 'Goldman Comment re: Enron issued this morning - Revised Price Target of $68/share',\n",
       " 'RE: Goldman Sachs $2.19 Natural GAs',\n",
       " 'Goldman Sachs $2.19 Natural GAs',\n",
       " 'RE: $25 million',\n",
       " '$25 million',\n",
       " 'RE: $25 million loan from EDf',\n",
       " '$25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " '$25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " 'RE: $25 million loan from EDf',\n",
       " '$25 million loan from EDf',\n",
       " 'A$M and its \"second tier\" status',\n",
       " 'A$M and its \"second tier\" status',\n",
       " 'A$M and its \"second tier\" status',\n",
       " 'UT/a$m business school and engineering school comparisons',\n",
       " 'Re: $',\n",
       " '$',\n",
       " 'Re: $',\n",
       " '$',\n",
       " '$$$$',\n",
       " 'FFL $$',\n",
       " 'RE: shipper imbal $$ collected',\n",
       " 'shipper imbal $$ collected',\n",
       " \"Oneok's Strangers Gas Payment $820,000\",\n",
       " \"Oneok's Strangers Gas Payment $820,000\",\n",
       " 'Another $40 Million?',\n",
       " 'FW: Entergy and FPL Group Agree to a $27 Billion Merger Of Equals',\n",
       " 'FW: Entergy and FPL Group Agree to a $27 Billion Merger Of Equals',\n",
       " 'Over $50 -- You made it happen!',\n",
       " 'Over $50 -- You made it happen!',\n",
       " 'FW: Co 0530 CINY 40781075  $5,356.46  FX Funding',\n",
       " 'Co 0530 CINY 40781075  $5,356.46  FX Funding',\n",
       " 'FW: Outstanding Young Alumni Travel Value to Amsterdam from $895',\n",
       " 'Outstanding Young Alumni Travel Value to Amsterdam from $895',\n",
       " 'RE: Modesto 7 MW COB deal @$19.3.',\n",
       " 'RE: Modesto 7 MW COB deal @$19.3.',\n",
       " 'Modesto 7 MW COB deal @$19.3.',\n",
       " 'Modesto 7 MW COB deal @$19.3.',\n",
       " 'RE: -$870K prior month adjustments',\n",
       " '-$870K prior month adjustments',\n",
       " 'RE: -$141,000 P&L hit on 8/13/01',\n",
       " '-$141,000 P&L hit on 8/13/01',\n",
       " '$$$',\n",
       " 'Re: DWR Stranded costs: $21 billion',\n",
       " 'CAISO cuts refund estimate to $6.1B from $8.9B',\n",
       " \"State's Power Purchases Costlier Than Projected Tab is $6 million a\",\n",
       " 'Fwd: Edison gets more time; Calif. may sell $14 bln bonds',\n",
       " 'Edison gets more time; Calif. may sell $14 bln bonds',\n",
       " 'Re: IDEA RE ISSUE OF UTILS IN CALIF WANTING $100 PRICE CAP',\n",
       " 'Back to $250 Cap in California',\n",
       " 'Energy Secretary Announces $350MM to Upgrade Path 15',\n",
       " 'RE: $.01 surcharge as \"tax\"',\n",
       " 'FW: $.01 surcharge as \"tax\"',\n",
       " 'FW: $.01 surcharge as \"tax\"',\n",
       " '$.01 surcharge as \"tax\"',\n",
       " \"California's $12.5 Bln Bond Sale May Be Salvaged, Official Says;\",\n",
       " \"RE: California's $12.5 Bln Bond Sale May Be Salvaged, Official\",\n",
       " \"RE: California's $12.5 Bln Bond Sale May Be Salvaged, Official Says; DWR Contract Renegotiation Is Key\",\n",
       " \"California's $12.5 Bln Bond Sale May Be Salvaged, Official Says; DWR Contract Renegotiation Is Key\",\n",
       " 'Re: Royal Bank of Canada - Wire ($2,529,352.58)',\n",
       " 'Free $10 Three Team Parlay',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'Blue Girl - $1.2MM option expires today - need to know whether to',\n",
       " 'FW: Economic Times article: FIs may take over Enron for $700-800m',\n",
       " 'FW: Economic Times article: FIs may take over Enron for $700-800m',\n",
       " 'FW: Economic Times article: FIs may take over Enron for $700-800m',\n",
       " 'Red Rock Delay $$ Impact',\n",
       " 'HandsFree Kits - $2',\n",
       " 'HandsFree Kits - $2',\n",
       " 'Re: The $10 you owe me',\n",
       " 'The $10 you owe me',\n",
       " 'RE: Enron files for Chapter 11 owing US$13B',\n",
       " 'Enron files for Chapter 11 owing US$13B',\n",
       " 'RE: $ allocation',\n",
       " '$ allocation',\n",
       " 'Re: Last chance: Save $100 on a future airline ticket',\n",
       " 'Re: ECS and the $500k reduction',\n",
       " 'Re: ECS and the $500k reduction',\n",
       " 'Re: ECS and the $500k reduction',\n",
       " 'Re: ECS and the $500k reduction',\n",
       " 'ECS and the $500k reduction',\n",
       " 'ECS and the $500k reduction',\n",
       " 'ECS and the $500k reduction',\n",
       " 'ECS and the $500k reduction',\n",
       " 'ECS and the $500k reduction',\n",
       " 'FW: Free Shipping & $1,300 in Savings',\n",
       " 'Free Shipping & $1,300 in Savings',\n",
       " 'RE: Free Shipping & $1,300 in Savings',\n",
       " 'RE: Free Shipping & $1,300 in Savings',\n",
       " 'FW: Free Shipping & $1,300 in Savings',\n",
       " 'Free Shipping & $1,300 in Savings',\n",
       " 'RE: Dynegy Is Mulling $2 Billion Investment In Enron in Possible',\n",
       " 'FW: Dynegy Is Mulling $2 Billion Investment In Enron in Possible \\tStep Toward Merger',\n",
       " 'FW: Dynegy Is Mulling $2 Billion Investment In Enron in Possible Step Toward Merger',\n",
       " 'Dynegy Is Mulling $2 Billion Investment In Enron in Possible Step Toward Merger',\n",
       " 'Peoples Gas --> $5,000 Invoice for Summer-Winter Exchange 6-1-00 to',\n",
       " 'Peoples Gas --> $5,000 Invoice for Summer-Winter Exchange 6-1-00 to',\n",
       " 'Peoples Gas --> $5,000 Invoice for Summer-Winter Exchange 6-1-00 to',\n",
       " 'Peoples Gas --> $5,000 Invoice for Summer-Winter Exchange 6-1-00 to',\n",
       " 'Re: short fall $971,443.11 for Wis Elect Power',\n",
       " 'Re: short fall $971,443.11 for Wis Elect Power',\n",
       " 'Re: short fall $971,443.11 for Wis Elect Power',\n",
       " 'Re: short fall $971,443.11 for Wis Elect Power',\n",
       " 'Re: short fall $971,443.11 for Wis Elect Power',\n",
       " 'short fall $971,443.11 for Wis Elect Power',\n",
       " 'RE: Q&A for NNG/TW Supported $1Billion Line of Credit',\n",
       " 'Q&A for NNG/TW Supported $1Billion Line of Credit',\n",
       " 'FW: Deals from $39 in our Las Vegas store!',\n",
       " '=09Deals from $39 in our Las Vegas store!',\n",
       " 'A trip worth $10,000 could be yours',\n",
       " 'A trip worth $10,000 could be yours',\n",
       " '142,000,000 Email Addresses for ONLY $149!!!!',\n",
       " \"Lou's $50,000\",\n",
       " \"Lou's $50,000\",\n",
       " \"Lou's $50,000\",\n",
       " 'Summary of $ at Risk for Customs',\n",
       " 'Summary of $ at Risk for Customs',\n",
       " 'Summary of $ at Risk for Customs',\n",
       " \"Calling All Investors: The New Power Company's IPO Priced at $21\",\n",
       " \"Calling All Investors: The New Power Company's IPO Priced at $21 P=\",\n",
       " 'Fenosa and Enron to Invest $550 Million in Dominican Republic',\n",
       " \"Enron Brazil To Invest $455 Million In Gas Distribution '01-'04\",\n",
       " 'RE: $5 million for 90 days?- how quaint!',\n",
       " 'FW: $5 million for 90 days?- how quaint!',\n",
       " '$5 million for 90 days?- how quaint!',\n",
       " 'RE: Wind $7MM',\n",
       " 'RE: Wind $7MM',\n",
       " 'RE: Wind $7MM',\n",
       " 'Wind $7MM',\n",
       " 'RE: Wind $7MM',\n",
       " 'Wind $7MM',\n",
       " 'Re: Counting the Cal ISO Votes for a $100 Price Cap',\n",
       " 'RE: C$ swap between EIM/ENA',\n",
       " 'C$ swap between EIM/ENA',\n",
       " \"Re: Where's My $20\",\n",
       " \"Re: Where's My $20\",\n",
       " \"Re: Where's My $20\",\n",
       " \"Re: Where's My $20\",\n",
       " 'Re: $100',\n",
       " 'Re: $100',\n",
       " 'Re: $100',\n",
       " \"Re: Where's My $20\",\n",
       " \"Re: Where's My $20\",\n",
       " 'RE: Eric Schroeder has just sent you $29.75 with PayPal',\n",
       " 'Fw: Eric Schroeder has just sent you $29.75 with PayPal',\n",
       " 'Eric Schroeder has just sent you $29.75 with PayPal',\n",
       " 'RE: Eric Schroeder has just sent you $29.75 with PayPal',\n",
       " 'Fw: Eric Schroeder has just sent you $29.75 with PayPal',\n",
       " 'Eric Schroeder has just sent you $29.75 with PayPal',\n",
       " 'RE: What are you talking about $1600?',\n",
       " 'Re: What are you talking about $1600?',\n",
       " 'RE: What are you talking about $1600?',\n",
       " 'RE: What are you talking about $1600?',\n",
       " '=09Re: What are you talking about $1600?',\n",
       " 'What are you talking about $1600?',\n",
       " 'What are you talking about $1600?',\n",
       " 'FW: Enron Seeks $2 Billion Cash Infusion As It Faces an Escalating',\n",
       " 'FW: Enron Seeks $2 Billion Cash Infusion As It Faces an Escalating Fiscal Crisis',\n",
       " 'Enron Seeks $2 Billion Cash Infusion As It Faces an Escalating Fiscal Crisis',\n",
       " 'The new, correct price is $67,776,700',\n",
       " 'Re: Demar request for $2.7 mm to pay out the Skandinavian now',\n",
       " 'Re: Demar request for $2.7 mm to pay out the Skandinavian now',\n",
       " 'RE: Transactions exceeding $100mil',\n",
       " 'Our benefits are about $50 per month higher with UBS',\n",
       " 'RE: $9.6MM EOL Gas Daily Issue',\n",
       " '$9.6MM EOL Gas Daily Issue',\n",
       " 'FW: NEAL - ITIN ONLY/$212.50',\n",
       " 'FW: NEAL - ITIN ONLY/$212.50',\n",
       " 'NEAL - ITIN ONLY/$212.50',\n",
       " 'FW: NEAL - ITIN ONLY/$212.50',\n",
       " 'FW: NEAL - ITIN ONLY/$212.50',\n",
       " 'NEAL - ITIN ONLY/$212.50',\n",
       " 'FW: Duke $',\n",
       " 'Duke $',\n",
       " 'RE: Duke $',\n",
       " 'FW: Duke $',\n",
       " 'FW: Duke $',\n",
       " 'Duke $',\n",
       " '$$$$',\n",
       " '$$$$',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'FW: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'FW: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'FW: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'FW: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'RE: Wire Detail for 10/25/01 wire for  $195,209.95',\n",
       " 'FW: DYN($42/sh)/ENE($7/sh) Merger At Risk. - Simmons and Company',\n",
       " 'FW: DYN($42/sh)/ENE($7/sh) Merger At Risk. - Simmons and Company latest thoughts',\n",
       " 'FW: DYN($42/sh)/ENE($7/sh) Merger At Risk. - Simmons and Company latest thoughts',\n",
       " \"FW: Re-Allocaton of $'s\",\n",
       " \"RE: Re-Allocaton of $'s\",\n",
       " \"Re-Allocaton of $'s\",\n",
       " \"Re-Allocaton of $'s\",\n",
       " 'RE: Wind $7MM',\n",
       " 'FW: Wind $7MM',\n",
       " 'Wind $7MM',\n",
       " 'RE: $9.92????????????',\n",
       " '$9.92????????????',\n",
       " 'RE: Below $10',\n",
       " 'Below $10',\n",
       " 'FW: Comments on the Status of ENE ($16/sh).',\n",
       " 'FW: Comments on the Status of ENE ($16/sh).',\n",
       " 'FW: Comments on the Status of ENE ($16/sh).',\n",
       " 'Breaking News : Williams Ordered to Pay $8 Million Refund to',\n",
       " 'Breaking News : Williams Ordered to Pay $8 Million Refund to Cal-ISO',\n",
       " 'Coho $500mm lawsuit against Hicks Muse',\n",
       " 'Coho $500mm lawsuit against Hicks Muse',\n",
       " 'Coho $500mm lawsuit against Hicks Muse',\n",
       " 'Re: $$$$',\n",
       " '$$$$',\n",
       " 'Perd $',\n",
       " 'Re: $80 million',\n",
       " 'Re: $80 million',\n",
       " '$80 million',\n",
       " '$80 million',\n",
       " 'Re: $80 million',\n",
       " '$80 million',\n",
       " '$80 million',\n",
       " 'Re: Calif Atty Gen Offers $50M Reward In Pwr Supplier',\n",
       " 'Financial Disclosure of $1.2 Billion Equity Adjustment',\n",
       " 'ENE: Despite Bounce It Appears Cheap; Yet $102 Target Likely a Late',\n",
       " 'ENE: Despite Bounce It Appears Cheap; Yet $102 Target Likely a Late 2002 Event:',\n",
       " 'Is it worth $200?',\n",
       " 'RE: #@$ !!!!!!!!',\n",
       " '$#%:#@$ !!!!!!!!',\n",
       " 'RE: @%$$@!!!',\n",
       " '=09@%$$@!!!',\n",
       " 'Special Offer: Switch to ShareBuilder and Get $50!',\n",
       " 'Amendment to Enron Corp. $25 Million guaranty of Enron Credit Inc.',\n",
       " 'RE: Amendment to Enron Corp. $25 Million guaranty of Enron Credit',\n",
       " 'Goldman Sach $ repo docs',\n",
       " 'Re: Goldman Sach $ repo docs',\n",
       " 'RE: Amendment to Enron Corp. $25 Million guaranty of Enron Credit',\n",
       " 'FW: Goldmans $1.5m',\n",
       " 'Goldmans $1.5m',\n",
       " 'FW: $1.5 Check',\n",
       " '$1.5 Check',\n",
       " 'RE: Goldman Sachs $',\n",
       " 'Goldman Sachs $',\n",
       " 'RE: TODAY ONLY - SAVE UP TO $120 EXTRA ON AIRLINE TICKETS!',\n",
       " 'RE: TODAY ONLY - SAVE UP TO $120 EXTRA ON AIRLINE TICKETS!',\n",
       " 'RE: $.01 surcharge as \"tax\"',\n",
       " 'RE: $.01 surcharge as \"tax\"',\n",
       " 'RE: $.01 surcharge as \"tax\"',\n",
       " 'FW: $.01 surcharge as \"tax\"',\n",
       " 'FW: $.01 surcharge as \"tax\"',\n",
       " '$.01 surcharge as \"tax\"',\n",
       " \"FW: PennFuture's E-Cubed - The $45 Million Rip Off\",\n",
       " \"=09PennFuture's E-Cubed - The $45 Million Rip Off\",\n",
       " 'RE: PaPUC assessment of $147,000 to Enron',\n",
       " 'Re: PaPUC assessment of $147,000 to Enron',\n",
       " 'PaPUC assessment of $147,000 to Enron',\n",
       " \"RE: ASAP!! EES' objections to PaPUC assessment of $147,000\",\n",
       " \"ASAP!! EES' objections to PaPUC assessment of $147,000\",\n",
       " 'RE: Pennsylvania $147,000 EES Assessment',\n",
       " '=09Pennsylvania $147,000 EES Assessment',\n",
       " 'FW: CAEM Study: Gas Dereg Has Saved Consumers $600B',\n",
       " 'CAEM Study: Gas Dereg Has Saved Consumers $600B',\n",
       " 'PaPUC assessment of $147,000 to Enron',\n",
       " \"RE: ASAP!! EES' objections to PaPUC assessment of $147,000\",\n",
       " \"ASAP!! EES' objections to PaPUC assessment of $147,000\",\n",
       " 'FW: Energy Novice to Be Paid $240,000',\n",
       " 'Energy Novice to Be Paid $240,000',\n",
       " 'RE:  $22.8 schedule C for BPA deal',\n",
       " '$22.8 schedule C for BPA deal',\n",
       " '$22.8 schedule C for BPA deal',\n",
       " 'origination $100k to Laird Dyer',\n",
       " 'Cd$ CME letter',\n",
       " 'Cd$ CME letter',\n",
       " '$',\n",
       " 'RE: $',\n",
       " 'RE: $',\n",
       " 'Re: $',\n",
       " 'RE: $',\n",
       " 'GET RICH ON $6.00 !!!',\n",
       " 'RE: Thoughts on the world of energy (OSX $77, XNG $183, XOI 496)',\n",
       " 'FW: Letter of Credit $ 5,500,000 in support of Transwestern',\n",
       " 'Letter of Credit $ 5,500,000 in support of Transwestern Pipeline Red Rock Expansion',\n",
       " 'Letter of Credit $ 5,500,000 in support of Transwestern Pipeline Red Rock Expansion',\n",
       " 'FW: shipper imbal $$ collected',\n",
       " 'shipper imbal $$ collected',\n",
       " 'FW: shipper imbal $$ collected',\n",
       " 'RE: shipper imbal $$ collected',\n",
       " 'shipper imbal $$ collected',\n",
       " 'FW: shipper imbal $$ collected',\n",
       " 'RE: shipper imbal $$ collected',\n",
       " 'shipper imbal $$ collected',\n",
       " \"FW: $$'s allocated to TW\",\n",
       " \"$$'s allocated to TW\",\n",
       " 'RE: email to USG confirming our decision not to require more LOC $',\n",
       " 'email to USG confirming our decision not to require more LOC $',\n",
       " '$',\n",
       " 'Re: Calpine Confirms $4.6B, 10-Yr Calif. Power Sales',\n",
       " 'RE: $2.15 bn Enron Metals Inventory Financings Closed',\n",
       " 'RE: $2.15 bn Enron Metals Inventory Financings Closed',\n",
       " 'FW: Thayer Aerospace Awarded $130 Million Vought Aircraft Contract',\n",
       " 'FW: Thayer Aerospace Awarded $130 Million Vought Aircraft Contract',\n",
       " 'Thayer Aerospace Awarded $130 Million Vought Aircraft Contract to',\n",
       " 're: mid-columbia $1 mm Schedule E difference',\n",
       " '$0.25 scheduling fee.',\n",
       " 'MPC $',\n",
       " 'RE: $10',\n",
       " 'RE: $10',\n",
       " 'RE: $10',\n",
       " '$10',\n",
       " 'RE: $10',\n",
       " '$10',\n",
       " 'FW: *** Gold/TSE GL/$US/CPI/TSE MM/CRB Bloomberg charts ***',\n",
       " 'FW: *** Gold/TSE GL/$US/CPI/TSE MM/CRB Bloomberg charts ***',\n",
       " 'FW: *** Gold/TSE GL/$US/CPI/TSE MM/CRB Bloomberg charts ***',\n",
       " 'FW: Summer Fare Sale From $128 Return!',\n",
       " 'Summer Fare Sale From $128 Return!']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in subjects if re.search(r\"\\$\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data, we can guess at the steps we'd need to do in order to figure out these values. We're going to ignore anything that doesn't have \"k\", \"million\" or \"billion\" after it as chump change. So what we need to find is: a dollar sign, followed by any series of numbers (or a period), followed potentially by a space (but sometimes not), followed by a \"k\", \"m\" or \"b\" (which will sometimes start the word \"million\" or \"billion\" but sometimes not... so we won't bother looking).\n",
    "\n",
    "Here's how I would translate that into a regular expression:\n",
    "\n",
    "    \\$[0-9.]+ ?(?:[Kk]|[Mm]|[Bb])\n",
    "    \n",
    "We can use `re.findall()` to capture all instances where we found this regular expression in the text. Here's what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$10M',\n",
       " '$10M',\n",
       " '$10M',\n",
       " '$10M',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$25 m',\n",
       " '$40 M',\n",
       " '$27 B',\n",
       " '$27 B',\n",
       " '$870K',\n",
       " '$870K',\n",
       " '$21 b',\n",
       " '$6.1B',\n",
       " '$8.9B',\n",
       " '$6 m',\n",
       " '$14 b',\n",
       " '$14 b',\n",
       " '$350M',\n",
       " '$12.5 B',\n",
       " '$12.5 B',\n",
       " '$12.5 B',\n",
       " '$12.5 B',\n",
       " '$1.2M',\n",
       " '$1.2M',\n",
       " '$1.2M',\n",
       " '$1.2M',\n",
       " '$1.2M',\n",
       " '$1.2M',\n",
       " '$1.2M',\n",
       " '$13B',\n",
       " '$13B',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$500k',\n",
       " '$2 B',\n",
       " '$2 B',\n",
       " '$2 B',\n",
       " '$2 B',\n",
       " '$1B',\n",
       " '$1B',\n",
       " '$550 M',\n",
       " '$455 M',\n",
       " '$5 m',\n",
       " '$5 m',\n",
       " '$5 m',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$2 B',\n",
       " '$2 B',\n",
       " '$2 B',\n",
       " '$2.7 m',\n",
       " '$2.7 m',\n",
       " '$100m',\n",
       " '$9.6M',\n",
       " '$9.6M',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$7M',\n",
       " '$8 M',\n",
       " '$8 M',\n",
       " '$500m',\n",
       " '$500m',\n",
       " '$500m',\n",
       " '$80 m',\n",
       " '$80 m',\n",
       " '$80 m',\n",
       " '$80 m',\n",
       " '$80 m',\n",
       " '$80 m',\n",
       " '$80 m',\n",
       " '$50M',\n",
       " '$1.2 B',\n",
       " '$25 M',\n",
       " '$25 M',\n",
       " '$25 M',\n",
       " '$1.5m',\n",
       " '$1.5m',\n",
       " '$45 M',\n",
       " '$45 M',\n",
       " '$600B',\n",
       " '$600B',\n",
       " '$100k',\n",
       " '$4.6B',\n",
       " '$2.15 b',\n",
       " '$2.15 b',\n",
       " '$130 M',\n",
       " '$130 M',\n",
       " '$130 M',\n",
       " '$1 m']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\$[0-9.]+ ?(?:[Kk]|[Mm]|[Bb])\", all_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to actually make a sum, though, we're going to need to do a little massaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34965734e+12\n"
     ]
    }
   ],
   "source": [
    "total_value = 0\n",
    "dollar_amounts = re.findall(r\"\\$\\d+ ?(?:[Kk]|[Mm]|[Bb])\", all_subjects)\n",
    "for amount in dollar_amounts:\n",
    "    # the last character will be 'k', 'm', or 'b'; \"normalize\" by making lowercase.\n",
    "    multiplier = amount[-1].lower()\n",
    "    # trim off the beginning $ and ending multiplier value\n",
    "    amount = amount[1:-1]\n",
    "    # remove any remaining whitespace\n",
    "    amount = amount.strip()\n",
    "    # convert to a floating-point number\n",
    "    float_amount = float(amount)\n",
    "    # multiply by an amount, based on what the last character was\n",
    "    if multiplier == 'k':\n",
    "        float_amount = float_amount * 1000\n",
    "    elif multiplier == 'm':\n",
    "        float_amount = float_amount * 1000000\n",
    "    elif multiplier == 'b':\n",
    "        float_amount = float_amount * 1000000000\n",
    "    # add to total value\n",
    "    total_value = total_value + float_amount\n",
    "\n",
    "print total_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number is so big that Python decided to use scientific notation! If we convert to an integer, we get around that problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349657340000\n"
     ]
    }
   ],
   "source": [
    "print int(total_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's over one trillion dollars! Nice work, guys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Finer-grained matches with grouping\n",
    "\n",
    "We used `re.search()` above to check whether or not a string matches a particular regular expression, in a context like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it was the best of times']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "dickens = [\n",
    "    \"it was the best of times\",\n",
    "    \"it was the worst of times\"]\n",
    "[line for line in dickens if re.search(r\"best\", line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the match object doesn't actually return `True` or `False`. If the search succeeds, the function returns something called a \"match object.\" Let's assign the result of `re.search()` to a variable and see what we can do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_sre.SRE_Match"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_string = \"this example has been used 423 times\"\n",
    "match = re.search(r\"\\d\\d\\d\", source_string)\n",
    "type(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a value of type `_sre.SRE_Match`. This value has several methods that we can use to access helpful and interesting information about the way the regular expression matched the string. [Read more about the methods of the match object here](https://docs.python.org/2/library/re.html#match-objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can see both where the match *started* in the string and where it *ended*, using the `.start()` and `.end()` methods. These methods return the indexes in the string where the regular expression matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print match.start()\n",
    "print match.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together, we can use these methods to grab exactly the part of the string that matched the regular expression, by using the start/end values to get a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'423'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_string[match.start():match.end()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it's so common, there's a shortcut for this operation, which is the match object's `.group()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'423'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.group()` method of a match object, in other words, returns exactly the part of the string that matched the regular expression.\n",
    "\n",
    "As an example of how to use the match object and its `.group()` method in context, let's revisit the example from above which found every subject line in the Enron corpus that had fifteen or more consecutive capital letters. In that example, we could only display the *entire subject line*. If we wanted to show just the part of the string that matched (i.e., the sequence of fifteen or more capital letters), we could use `.group()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "PLEEEEEEEEEEEEEEEASE\n",
      "ACCOMPLISHMENTS\n",
      "ACCOMPLISHMENTS\n",
      "CONFIDENTIALITY\n",
      "CONFIDENTIALITY\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "ACKNOWLEDGEMENT\n",
      "ACKNOWLEDGEMENT\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "INTERCONNECTION\n",
      "INTERCONNECTION\n",
      "INTERCONNECTION\n",
      "INTERCONNECTION\n",
      "INTERCONNECTION\n",
      "CONGRATULATIONS\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "WASSSAAAAAAAAAAAAAABI\n",
      "NOOOOOOOOOOOOOOOO\n",
      "NOOOOOOOOOOOOOOOO\n",
      "NOOOOOOOOOOOOOOOO\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "CONFIDENTIALITY\n",
      "CONFIDENTIALITY\n",
      "ACCOMPLISHMENTS\n",
      "ACCOMPLISHMENTS\n",
      "CONGRATULATIONS\n",
      "STANDARDIZATION\n",
      "STANDARDIZATION\n",
      "STANDARDIZATION\n",
      "STANDARDIZATION\n",
      "BRRRRRRRRRRRRRRRRRRRRR\n",
      "CONGRATULATIONS\n",
      "CONGRATULATIONS\n",
      "NETCOTRANSMISSION\n",
      "NETCOTRANSMISSION\n",
      "NETCOTRANSMISSION\n",
      "INTERCONTINENTAL\n",
      "INTERCONTINENTAL\n"
     ]
    }
   ],
   "source": [
    "for line in subjects:\n",
    "    match = re.search(r\"[A-Z]{15,}\", line)\n",
    "    if match:\n",
    "        print match.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to remember about `re.search()` is that it returns `None` if there is no match. For this reason, you always need to check to make sure the object is *not* `None` before you attempt to call the value's `.group()` method. This is the reason that it's difficult to write the above example as a list comprehension---you need to check the result of `re.search()` before you can use it. An attempt to do something like this, for example, will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-666f9b5fe0ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[A-Z]{15,}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "[re.search(r\"[A-Z]{15,}\", line).group() for line in subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python complains that `NoneType` has no `group()` method. This happens because sometimes the result of `re.search()` is none.\n",
    "\n",
    "We could, of course, write a little function to get around this limitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a function\n",
    "def filter_and_group(source, regex):\n",
    "    return [re.search(regex, item).group() for item in source if re.search(regex, item)]\n",
    "\n",
    "# now call it\n",
    "filter_and_group(subjects, r\"[A-Z]{15,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Multiple groups in one regular expression\n",
    "\n",
    "So `re.search()` lets us get the parts of a string that match a regular expression, using the `.group()` method of the match object it returns. You can get even finer-grained matches using a feature of regular expressions called *grouping*.\n",
    "\n",
    "Let's start with a toy example. Say you have a list of University courses in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courses = [\n",
    "    \"CSCI 105: Introductory Programming for Cat-Lovers\",\n",
    "    \"LING 214: Pronouncing Things Backwards\",\n",
    "    \"ANTHRO 342: Theory and Practice of Cheesemongery (Graduate Seminar)\",\n",
    "    \"CSCI 205: Advanced Programming for Cat-Lovers\",\n",
    "    \"ENGL 112: Speculative Travel Writing\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to extract the following items from this data:\n",
    "\n",
    "* A unique list of all departments (e.g., CSCI, LING, ANTHRO, etc.)\n",
    "* A list of all course names\n",
    "* A dictionary with all of the 100-level classes, 200-level classes, and 300-level classes\n",
    "\n",
    "Somehow we need to get *three* items from each line of data: the department, the number, and the course name. You can do this easily with regular expressions using *grouping*. To use grouping, put parentheses (`()`) around the portions of the regular expression that are of interest to you. You can then use the `.groups()` (note the `s`!) function to get the portion of the string that matched the portion of the regular expression inside the parentheses individually. Here's what it looks like, just operating on the first item of the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_course = courses[0]\n",
    "match = re.search(r\"(\\w+) (\\d+): (.+)$\", first_course)\n",
    "match.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression in `re.search()` above roughly translates as the following:\n",
    "\n",
    "* Find me a sequence of one or more alphanumeric characters. Save this sequence as the first group.\n",
    "* Find a space.\n",
    "* Find me a sequence of one or more digits. Save this as the second group.\n",
    "* Find a colon followed by a space.\n",
    "* Find me one or more characters---I don't care which characters---and save the sequence as the third group.\n",
    "* Match the end of the line.\n",
    "\n",
    "Calling the `.groups()` method returns a tuple containing each of the saved items from the grouping. You can use it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = match.groups()\n",
    "print \"Department:\", groups[0] # department\n",
    "print \"Course number:\", groups[1] # course number\n",
    "print \"Course name:\", groups[2] # course name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's iterate over the entire list of courses and put them in the data structure as appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departments = set()\n",
    "course_names = []\n",
    "course_levels = {}\n",
    "for item in courses:\n",
    "    # search and create match object\n",
    "    match = re.search(r\"(\\w+) (\\d+): (.+)$\", item)\n",
    "    if match: # if there's a match...\n",
    "        groups = match.groups() # get the groups: 0 is department, 1 is course number, 2 is name\n",
    "        departments.add(groups[0]) # add to department set (we wanted a list of *unique* departments)\n",
    "        course_names.append(groups[2]) # add to list of courses\n",
    "        level = int(groups[1]) / 100 # get the course \"level\" by dividing by 100\n",
    "        # add the level/course key-value pair to course_levels\n",
    "        if level not in course_levels:\n",
    "            course_levels[level*100] = []\n",
    "        course_levels[level*100].append(groups[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this cell, you can check out the unique list of departments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the list of course names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "course_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the dictionary that maps course \"levels\" to a list of courses at that level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "course_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Grouping with multiple matches in the same string\n",
    "\n",
    "A problem with `re.search()` is that it only returns the *first* match in a string. What if we want to find *all* of the matches? It turns out that `re.findall()` *also* supports the regular expression grouping syntax. If the regular expression you pass to `re.findall()` includes any grouping parentheses, then the function returns not a list of strings, but a list of tuples, where each tuple has elements corresponding in order to the groups in the regular expression.\n",
    "\n",
    "As a quick example, here's a test string with number names and digits, and a regular expression to extract all instances of a series of alphanumeric characters, followed by a space, followed by a single digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', '1'), ('two', '2'), ('three', '3'), ('four', '4'), ('five', '5')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"one 1 two 2 three 3 four 4 five 5\"\n",
    "re.findall(r\"(\\w+) (\\d)\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to extract every phone number from the Enron subjects corpus, separating out the components of the numbers by group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('713', '853', '4743'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('713', '222', '7667'),\n",
       " ('281', '296', '0573'),\n",
       " ('713', '851', '2499'),\n",
       " ('713', '345', '7896'),\n",
       " ('713', '345', '7896'),\n",
       " ('713', '345', '7896'),\n",
       " ('713', '345', '7896'),\n",
       " ('713', '345', '7896'),\n",
       " ('281', '367', '8953'),\n",
       " ('713', '528', '0759'),\n",
       " ('713', '850', '9002'),\n",
       " ('713', '703', '8294'),\n",
       " ('614', '888', '9588'),\n",
       " ('713', '767', '8686'),\n",
       " ('303', '571', '6135'),\n",
       " ('281', '537', '9334'),\n",
       " ('800', '937', '6563'),\n",
       " ('800', '937', '6563'),\n",
       " ('888', '296', '1938')]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(\\d\\d\\d)-(\\d\\d\\d)-(\\d\\d\\d\\d)\", all_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can do a quick little data analysis on the frequency of area codes in these numbers, using the [Counter](https://docs.python.org/2/library/collections.html#counter-objects) object from the `collections` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('713', 21)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "area_codes = [item[0] for item in re.findall(r\"(\\d\\d\\d)-(\\d\\d\\d)-(\\d\\d\\d\\d)\", all_subjects)]\n",
    "count = Counter(area_codes)\n",
    "count.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Multiple match objects with `re.finditer()`\n",
    "\n",
    "The `re` library also has a `re.finditer()` function, which returns not a list of matching strings in tuples (like `re.findall()`), but an iterator of *match objects*. This is useful if you need to know not just which text matched, but *where* in the text the match occurs. So, for example, to find the positions in the `all_subjects` corpus where the word \"Oregon\" occurs, regardless of capitalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(410338, 410344, 'Oregon'),\n",
       " (410353, 410359, 'Oregon'),\n",
       " (608654, 608660, 'Oregon'),\n",
       " (831605, 831611, 'Oregon'),\n",
       " (3059955, 3059961, 'Oregon'),\n",
       " (3640267, 3640273, 'Oregon'),\n",
       " (3640292, 3640298, 'Oregon'),\n",
       " (3640317, 3640323, 'Oregon'),\n",
       " (3640610, 3640616, 'Oregon'),\n",
       " (3640635, 3640641, 'Oregon'),\n",
       " (3640660, 3640666, 'Oregon'),\n",
       " (4385798, 4385804, 'oregon')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.start(), match.end(), match.group()) for match in re.finditer(r\"[Oo]regon\", all_subjects)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conclusion\n",
    "\n",
    "Regular expressions are a great way to take some raw text and find the parts that are of interest to you. Python's string methods and string slicing syntax are a great way to massage and clean up data. You know them both now, which makes you powerful. But as powerful as you are, you have only scratched the surface of your potential! We only scratched the surface of what's possible with regular expressions. Here's some further reading:\n",
    "\n",
    "* [egrep for Linguists](http://stts.se/egrep_for_linguists/egrep_for_linguists.html) explains how to use regular expressions using the command-line tool `egrep` (which I recommend becoming familiar with!)\n",
    "* Once you've mastered the basics, check the official [Python regular expressions HOWTO](https://docs.python.org/2.7/howto/regex.html). The official [Python documentation on regular expressions](https://docs.python.org/2/library/re.html) is a deep dive on the subject.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
